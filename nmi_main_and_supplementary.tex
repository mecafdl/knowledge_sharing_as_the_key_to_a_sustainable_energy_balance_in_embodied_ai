% Use only LaTeX2e, calling the article.cls class and 12-point type.

\documentclass[12pt]{article}
%\usepackage[textwidth=18.5cm]{geometry}
\usepackage[textwidth=18.5cm, textheight=26cm]{geometry}
%\usepackage[a4paper, total={8in, 11in}, margin=1in]{geometry}
% Users of the {thebibliography} environment or BibTeX should use the
% scicite.sty package, downloadable from *Science* at
% http://www.sciencemag.org/authors/preparing-manuscripts-using-latex 
% This package should properly format in-text
% reference calls and reference-list numbers.

\usepackage{adjustbox}
%\usepackage{scicite}

\usepackage{times}
% \usepackage{units}

%\usepackage[T1]{fontenc}
%\usepackage[ngerman]{babel}
\usepackage[english]{babel}
\usepackage{empheq}

\usepackage[]{graphicx}
\graphicspath{ {./fig/} }
\usepackage[utf8]{inputenc}
\usepackage{subcaption}
\usepackage[labelformat=simple]{subcaption}  
\captionsetup[subfigure]{font={bf,small}, skip=1pt, margin=-0.1cm, singlelinecheck=false}
\usepackage[labelfont=bf]{caption}
\captionsetup{labelfont=bf}
\captionsetup{font=footnotesize}


\usepackage{amsmath}
\usepackage{booktabs} % Add this to your preamble
\usepackage{adjustbox} % Already used
\usepackage{array} % For better column formatting
\usepackage{amssymb}
\usepackage{cancel}
\usepackage{dirtytalk}
\usepackage{fourier}
\usepackage{siunitx}
\usepackage{tcolorbox}
\usepackage{textgreek}
\usepackage{wrapfig}
\usepackage{tikz}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
		\node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

% Added by authors
\usepackage{siunitx}
\usepackage{tabularx,ragged2e,booktabs}
\usepackage{multirow}
\usepackage{lipsum}
\usepackage{bm}
\usepackage{mathtools}
\captionsetup[figure]{name={Fig.},labelsep=period}
%\captionsetup[table]{name={Table},labelsep=period}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\usepackage{hyperref}
\urlstyle{same}

\usepackage{xr}

\usepackage{caption}
% \captionsetup[table]{skip=1pt} 

\usepackage[nolist]{acronym}
\newacro{ai}[AI]{artificial intelligence}
\newacro{dai}[DAI]{disembodied artificial intelligence}
\newacro{eai}[EAI]{embodied artificial intelligence}

\newacro{gpu}[GPU]{graphics processing unit}
\newacro{cce}[CCE]{computation and communication energy}
\newacro{bbe}[BBE]{body basal energy}
\newacro{mie}[MIE]{motion and interaction energy}


\newacro{isl}[IsL]{isolated learning}
\newacro{il}[IL]{incremental learning}
\newacro{tl}[TL]{transfer learning}
\newacro{til}[TIL]{transfer with incremental learning}
\newacro{cl}[CL]{collective learning}
\newacro{dcl}[DCL]{distributed collective learning}
\newacro{slad}[SLAD]{simultaneous learning and discovery}

\newacro{c1}[C1]{first energy challenge}
\newacro{c2}[C2]{second energy challenge}
\newacro{c3}[C3]{third energy challenge}


\externaldocument{supplementary_materials}


%\usepackage[demo]{graphicx}
%\usepackage{ifdraft}
%\ifdraft{\renewcommand{\includegraphics}{\relax}}{\relax}
%\usepackage{comment}
%\excludecomment{figure}
%\let\endfigure\relax


\newcommand\hl[1]{\colorbox{yellow}{\textcolor{red}{#1}}}
\newcommand\myhl[1]{\textcolor{blue}{#1}}



% Use this to display line numbers
% \usepackage{lineno}
% \linenumbers

\DeclareMathAlphabet\mathbfcal{OMS}{cmsy}{b}{n}
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}
\renewcommand{\emph}[1]{\textit{#1}}
\let\textcircledold\textcircled

\newcommand{\collective}{\emph{collective}}

\renewcommand{\textcircled}[1]{\raisebox{.5pt}{\textcircledold{\raisebox{-.45pt} {#1}}}}
\newcommand*{\important}[1]{\textcolor{red}{\danger~\textbf{IMPORTANT:~}} \textcolor{red}{#1}}
\newcommand*{\pending}[1]{\textcolor{blue}{$\bigstar$~\textbf{PENDING~#1}}}
\newcommand\mybox[2][]{\tikz[overlay]\node[fill=blue!100,inner sep=4pt, anchor=text, rectangle, rounded corners=1mm,#1] {#2};\phantom{#2}}

\newcommand{\TODO}[1]{\mybox[fill=yellow]{\textcolor{blue}{\warning~\Large \textbf{TODO}}:~\textcolor{blue}{\textbf{\emph{#1}}}}}
\newcommand{\xmark}{\ding{55}}%
\newcommand{\textcircledD}[1]{\raisebox{.9pt}{\textcircled{\raisebox{+.5pt} {\footnotesize#1}}}}
\newcommand{\diaz}[1]{\textcolor{blue}{[Diaz: #1]}}
\newcommand{\haddadin}[1]{\textcolor{red}{[Haddadin: #1]}}
\newcommand{\del}[1]{\textcolor{orange}{\xout{#1}}}
\newcommand{\new}[1]{\textcolor{orange}{#1}}
\DeclareMathOperator*{\E}{\mathbb{E}}
\renewcommand{\thesubfigure}{\textbf{\Alph{subfigure}}}
% \newtheorem{assumption}{Modeling Assumption}

\usepackage{amsthm, thmtools}
\declaretheoremstyle[
  spaceabove=0pt,          % no space before
  spacebelow=0pt,          % no space after
  headpunct={},            % no punctuation after the head
  postheadspace=0pt,       % no space after the head
  bodyfont=\itshape,       % as you like
  headfont=\bfseries
]{intable}

\declaretheorem[name=Assumption,style=intable]{newassumption}

\newtheoremstyle{mytheoremstyle}  % name
  {1pt}                          % Space above
  {1pt}                          % Space below
  {\itshape}                      % Body font
  {}                              % Indent amount
  {\bfseries}                     % Theorem head font
  {!}                             % Punctuation after theorem head
  {5pt plus 1pt minus 1pt}        % Space after theorem head
  {}                              % Theorem head spec

\newtheoremstyle{tight}%
  {6pt}{6pt}% Space above/below
  {\itshape}{}{\bfseries}{.}{5pt plus 1pt minus 1pt}{}


% \theoremstyle{mytheoremstyle}
\theoremstyle{tight}
\newtheorem{assumption}{Assumption}


\newtheorem{definition}{Definition}

\renewcommand{\figurename}{Fig.}


%% MY ADDED SECTION
\usetikzlibrary{backgrounds}
\makeatletter

\tikzset{%
	fancy quotes/.style={
		text width=\fq@width pt,
		align=justify,
		inner sep=1em,
		anchor=north west,
		minimum width=\linewidth,
	},
	fancy quotes width/.initial={.8\linewidth},
	fancy quotes marks/.style={
		scale=8,
		text=white,
		inner sep=0pt,
	},
	fancy quotes opening/.style={
		fancy quotes marks,
	},
	fancy quotes closing/.style={
		fancy quotes marks,
	},
	fancy quotes background/.style={
		show background rectangle,
		inner frame xsep=0pt,
		background rectangle/.style={
			fill=gray!25,
			rounded corners,
		},
	}
}

\newenvironment{fancyquotes}[1][]{%
	\noindent
	\tikzpicture[fancy quotes background]
	\node[fancy quotes opening,anchor=north west] (fq@ul) at (0,0) {``};
	\tikz@scan@one@point\pgfutil@firstofone(fq@ul.east)
	\pgfmathsetmacro{\fq@width}{\linewidth - 2*\pgf@x}
	\node[fancy quotes,#1] (fq@txt) at (fq@ul.north west) \bgroup
}
{\egroup;
	\node[overlay,fancy quotes closing,anchor=east] at (fq@txt.south east) {''};
	\endtikzpicture}

\makeatother
\newcommand{\task}{\ensuremath{\tau}}
\newcommand{\sltwoi}{\ensuremath{t_l}} %single learning time without index
\newcommand{\slt}[1]{\ensuremath{t_{l,#1}}} %... with index
\newcommand{\tlt}{\ensuremath{T}} %total learning time
\newcommand{\comp}{\ensuremath{c}} %complexity (learning time from scratch)
\newcommand{\diste}[1]{\ensuremath{\mathrm{d}(\task_{#1},\{ \})}}
\newcommand{\dist}[2]{\ensuremath{\mathrm{d}(\task_{#1},\{\task_1, \task_2, \dots, \task_{#2}\})}}
\newcommand{\En}{\ensuremath{E}}
\newcommand{\opt}{\ensuremath{\mathrm{opt}}}
\newcommand{\tot}{\ensuremath{\mathrm{tot}}}
\newcommand{\Opt}{\ensuremath{\mathrm{Opt}}}
\newcommand{\densMan}{\ensuremath{\rho_{\mathrm{man}}}} %manufacturing energy density
\newcommand{\Tau}{\ensuremath{\mathcal{T}}}

\newcommand{\redtext}[1]{\textcolor{red}{#1}}
\setlength{\columnsep}{1cm}

\newtheorem{challenge}{\textbf{CHALLENGE}}

\renewcommand{\arraystretch}{2} 

% The preamble here sets up a lot of new/revised commands and
% environments.  It's annoying, but please do *not* try to strip these
% out into a separate .sty file (which could lead to the loss of some
% information when we convert the file to other formats).  Instead, keep
% them in the preamble of your main LaTeX source file.


% The following parameters seem to provide a reasonable page setup.
\topmargin 0.0cm
\oddsidemargin 0.2cm
\textwidth 16cm 
\textheight 21cm
\footskip 1.0cm


%The next command sets up an environment for the abstract to your paper.
\newenvironment{sciabstract}{%
\begin{quote} \bf}
{\end{quote}}


% Include your paper's title here
\title{Collective Simultaneous Learning and Discovery of Knowledge for Scalable Yet Sustainable Embodied AI}


% Place the author information here.  Please hand-code the\\
% information and notecalls; do *not* use \footnote commands.  Let the
% author contact information appear immediately below the author names
% as shown.  We would also prefer that you don't change the type-size
% settings shown here.

\author
{Fernando D\'iaz Ledezma$ {}^{1}$ and Sami Haddadin${}^{2,\ast}$
	\\
	\normalsize{${}^{1}$TUM - Technical University of Munich}\\
	\normalsize{${}^{2}$MBZUAI - Mohamed bin Zayed University of Artificial Intelligence}\\
	\\
	\normalsize{$^\ast$To whom correspondence should be addressed; E-mail: \url{sami.haddadin@mbzuai.ac.ae}}
}
% Include the date command, but leave its argument blank.

\date{}



%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%



\begin{document} 
% Double-space the manuscript.

\baselineskip24pt

% Make the title.

\maketitle 



% Place your abstract within the special {sciabstract} environment.
\begin{sciabstract}
	\textbf{Abstract:}
    The growing energy demands of large-scale \ac{eai} present a major sustainability challenge. Conventional learning paradigms are inefficient because they neglect inter-agent knowledge sharing, resulting in redundant energy use as agents repeatedly acquire skills that are already possessed by themselves or their peers. We position \ac{cl}, a paradigm that enables structured inter-agent knowledge exchange, as the solution to realizing a synergistic and scalable learning system. In a smart factory case study, \ac{cl} masters a complex skill universe with significant energy savings compared to the best non-sharing alternative. These gains arise from zero-shot skill acquisition, which minimizes production downtime. We present a dynamical systems model that explains this emergent efficiency, showing how \ac{cl} operates in a synergistic regime that overcomes the limitations of neglecting inter-agent knowledge sharing. This work provides a scalable framework for energetically sustainable \ac{eai}.
\end{sciabstract}

%\textbf{One-Sentence Summary:} Embracing collective learning in (embodied) AI reduces energy consumption and accelerates skill acquisition by orders of magnitude.

% In setting up this template for *Science* papers, we've used both
% the \section* command and the \paragraph* command for topical
% divisions.  Which you use will of course depend on the type of paper
% you're writing.  Review Articles tend to have displayed headings, for
% which \section* is more appropriate; Research Articles, when they have
% formal topical divisions at all, tend to signal them with bold text
% that runs into the paragraph, for which \paragraph* is the right
% choice.  Either way, use the asterisk (*) modifier, as shown, to
% suppress numbering.

%%%%%% Main Text %%%%%%

\newcommand{\beginsupplement}
{%
	\setcounter{table}{0}
	\renewcommand{\thesection}{S\arabic{section}}
	\renewcommand{\thetable}{S\arabic{table}}%
	\setcounter{figure}{0}
	\renewcommand{\thefigure}{S\arabic{figure}}%
}

% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
Rapid advancements driven by \ac{ai} come at a substantial and escalating energy cost, presenting significant grand energy challenges \cite{Strubell2019EnergyPolicyConsiderations,Vries2023growingenergyfootprint,Cao2020TowardsAccurateReliable}. The \textbf{\ac{c1}} is the immense computational power required for training and deploying \ac{ai} models, which has led to a clear spike in energy consumption from data centers globally---a figure estimated to have reached 220-320~\unit{\tera\watt\hour} in 2021 \cite{Thomas2023cloudusesmassive,Vanian2023ChatGPTgenerativeAI,Corbyn2023Nvidiachipmaker,IEA2025_EnergyAndAI}. The \textbf{\ac{c2}} is the escalating energy demand from the rapid proliferation of physical robots, with the installed base growing 350\% in a decade to approximately 4.2 million units, an expansion dubbed the ``Cambrian explosion'' of robotics \cite{Pratt2015Iscambrianexplosion,IFR2024WorldRobotics2024}. Finally, the \textbf{\ac{c3}} is the often-overlooked energetic expenditure associated with the actual manufacture of the hardware required for \ac{ai} and robotics. An expanded discussion of these challenges is provided in the \nameref{sec:supplementary_materials} Sec.~\ref{sec:ai_grand_challenges}.

These grand energy challenges are particularly acute and fundamentally intertwined in \ac{eai}, the integration of \ac{ai} and robotics \cite{Pfeifer2004Embodiedartificialintelligence}. Unlike \ac{dai}---see Fig.~\ref{fig:eai_and_dai_concept_figure}~\textbf{A}---, which often relies on passively collected data for a sequential, one-off learning process, \ac{eai} agents are locked in a causally-coupled cyclic process with the physical world (Fig.~\ref{fig:eai_and_dai_concept_figure}~\textbf{B}). They must learn through continuous, energy-expending interaction, where active data generation and learning processes demand constant physical action \cite{Chebotar2019Closingsimreal}. Mastering skills in the physical realm requires continuous and repeated execution, consuming energy for motion and interaction in each instance, a cost \ac{dai} systems do not incur.

% ---
\begin{figure*}[t!]
	\centering
	\hspace*{\fill}
	\includegraphics[width=0.95\textwidth]{eai_energy_categories_v3.png}
	\hspace*{\fill}
	\caption[] {\label{fig:eai_energy_categories} \textbf{Energy expenditures of an \ac{eai} agent.} {Three fundamental energy expenditure categories are identified during the planning, learning, and execution of a skill by an \ac{eai} agent.}}
\end{figure*}
% ---

To analyze this, we formalize the energetic expenditure of a prototypical \ac{eai} agent into three fundamental categories (Fig.~\ref{fig:eai_energy_categories}): \textbf{\ac{cce}} for planning, querying, exploration, and training routines; \textbf{\ac{bbe}} for the agent's basic operational functions, such as standby power, proprioceptive intelligence, or gravity compensation; and \textbf{\ac{mie}} for the physical execution of a specific skill. The total energy demand of an \ac{eai} system $E_{\tau}$ is the sum of these costs.~%, repeated over countless learning episodes, and scaled by the number of agents.
It is crucial to distinguish these agent-dependent costs from the agent-independent, theoretical minimum energy $E_{\tau}^{*}$ required to perform a skill $\tau$ (for example, the physics-defined energy to move an object from an initial to a final location). The total energy expended by the agent is vastly greater than this irreducible minimum ($E_T \gg E_{\tau}^{*}$). This difference, representing the ``learning energy'' and body-dependent overhead, is the primary target for energy  (see Sec.~\ref{sec:dai_and_eai} for more details).

As robotic deployments scale to fleets of thousands or millions, contemporary learning paradigms---such as isolated, incremental, and transfer learning---become fundamentally unsustainable. Within the scope of our framework, these paradigms are interpreted as mechanisms for organizing knowledge strictly at the level of individual agents. While \ac{il} captures the sequential buildup of knowledge from highly similar skills and \ac{tl} formalizes how previously acquired knowledge accelerates learning of related yet semantically separated skill clusters, both remain inherently single-agent phenomena. In these approaches, each agent learns largely in isolation, lacking mechanisms for systematic, structured knowledge sharing. This isolation leads to rampant redundancy, with agents independently expending \ac{cce} and \ac{mie} to re-acquire skills that may have already been mastered by their peers. Consequently, this results in an inefficient partitioning of knowledge across the \collective~(as explored in Fig.~\ref{fig:learning_paradigms_and_size_of_collective}), where the system's total knowledge is fragmented rather than shared. Thus, scalability---which should be an advantage---becomes a penalty that multiplies energy inefficiency. Our framework extends this view by shifting the paradigm from isolated knowledge accumulation to distributed, interactive, and continuously evolving learning dynamics.

Here, we position \acl{cl} \cite{Haddadin2014SystemzumErstellen,Haddadin2015Systemgeneratingsets}, as the paradigm that fundamentally reframes this problem. \Ac{cl} capitalizes on inter-agent connectivity to enable the structured sharing, integration, and composition of knowledge, transforming a fragmented \collective~into a synergistic ``Network of Knowledge.'' We hypothesize that \ac{cl} can overcome the limitations of knowledge partitioning and dramatically reduce the energy consumption of large-scale \ac{eai} systems by an order of magnitude compared to conventional learning paradigms that neglect inter-agent knowledge sharing.

To test this hypothesis, we develop a dynamical systems model of \ac{cl} that describes how a \collective~of agents acquires a universe of skills distributed over a structured ``skill manifold.'' We validate this model's performance in a smart factory case study, simulating a fleet of robots learning skills for flexible manufacturing. Our results demonstrate that \ac{cl} enables the \collective~to acquire all necessary skills using only about 10\% of the energy required by the closest conventional alternative (transfer-with-incremental-learning). This efficiency, which stems from the synergistic integration of shared knowledge, allows the \ac{cl} system to achieve zero-shot learning for new tasks, virtually eliminating production downtime (detailed in Fig.~\ref{fig:smart_factory_case_study}). We show that this success is achieved by operating in an ideal, synergistic learning regime, establishing a scalable, efficient, and sustainable framework for the future of \ac{eai}.

% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
\section{Results}\label{sec:results}
% ---
\begin{figure*}[t!]
	\centering
	\hspace*{\fill}
	\includegraphics[width=16cm]{smart_factory_case_study.png}
	\hspace*{\fill}
	\caption[] {\label{fig:smart_factory_case_study} \textbf{Smart sensor manufacturing.} {(\textbf{A}) A factory manufactures a new smart sensor every shift. During downtime, a robot \collective~might need to learn a new set of skills to manufacture the new sensor. (\textbf{B}) The skills seen by the \collective, according to the number of products, (\textbf{C}), the learning episodes required to learn a product, and (\textbf{D}), the total learning energy $E_\mathcal{S}$ required to master all skills.
    }}
\end{figure*}
% ---

% ===================================================================================================
\subsection{\Acl{cl} reduces energy consumption}
To ground our hypothesis in a practical application, we first present a case study of a smart factory (see \nameref{sec:supplementary_materials} Sec.~\ref{sec:cl_scenarios_supplementaries} for further details). This scenario models a \collective~of $N_\mathrm{r} = 8$ robots tasked with learning a universe of $N_\mathcal{S}=512$ skills, grouped into $N_\mathcal{Z}=4$ distinct clusters of highly similar skills, required to manufacture advanced smart sensors. The factory utilizes flexible, reconfigurable work cells, meaning a production changeover to a new sensor type requires a new set of skills to be learned by the \collective. This learning phase represents production downtime, which incurs significant costs in both manufacturing time and energy consumption (Fig.~\ref{fig:smart_factory_case_study}~\textbf{A}).

For example, a switch from manufacturing Product A (requiring skills from clusters $\mathcal{Z}_1$, $\mathcal{Z}_2$, and  $\mathcal{Z}_4$) to Product B (requiring skills from $\mathcal{Z}_1$, $\mathcal{Z}_3$, and $\mathcal{Z}_4$) necessitates that the robot \collective~learns a subset of new skills from cluster $\mathcal{Z}_3$.

% We simulated this scenario to compare the performance of \ac{cl} against conventional learning paradigms that neglect inter-agent knowledge sharing; namely, \ac{isl}, \ac{il}, and \ac{til}. To quantify the energy cost, we first estimated the power per learning episode ($P_0$) by summing the \ac{bbe}, \ac{mie}, and \ac{cce} expenditures ($P_\mathrm{BBE} + P_\mathrm{MIE} + P_\mathrm{CCE}$) for a representative \ac{eai} agent, which totaled approximately $1.76~\text{kW}$. Assuming a 60-second duration ($\Delta t$) for an average learning trial, the energy cost of a single learning episode was estimated at $e_0 \approx 105~\text{kJ}$ (see \nameref{sec:supplementary_materials} Sec.~\ref{sec:eia_agent_reference_values} for full derivation).
We ran multiple Monte Carlo simulations of this scenario to account for the stochastic nature of some of the \ac{cl} model parameters, see \nameref{sec:methods}. We then compared the performance of \ac{cl}---selecting the model parameters to operate in the \textit{ideal synergistic regime} of knowledge sharing dynamics---against conventional learning paradigms that neglect inter-agent knowledge sharing; namely, \ac{isl}, \ac{il}, and \ac{til}. To quantify the total skill learning energy $E_\mathcal{S}$, we consider it to be directly proportional to the number of trial episodes $C_\mathcal{S}$ required to learn all skills and the basic learning energy per trial episode $e_0$ (see \nameref{sec:supplementary_materials} Sec.~\ref{sec:energy_time_and_power_per_episode} for full derivation).

The results demonstrate a dramatic and fundamental difference in efficiency. Figure~\ref{fig:smart_factory_case_study}~\textbf{B} tracks the learning progress as the number of different products manufactured increases. Under the CL paradigm, the \collective's shared knowledge base expands rapidly through inter-agent communication. As shown in Fig.~\ref{fig:smart_factory_case_study}~\textbf{C}, this leads to an exponential decrease in the number of learning episodes required for each new product. After approximately 20 product changeovers, the \ac{cl} system achieves a ``zero-shot learning'' frontier; the knowledge required for entirely new products is already contained within the \collective's shared memory from previously learned skills. This synergistic composition, unique to \ac{cl}, virtually eliminates the downtime and energy expenditure needed for new product adaptation.

In stark contrast, the conventional paradigms fail to scale. \ac{isl} requires a constant, high number of episodes for every new skill. \ac{il} and \ac{til} exhibit modest improvement but are fundamentally limited because knowledge is never shared between agents; each robot must learn independently without leveraging what its peers already know.

This performance gap translates directly to a massive difference in energy consumption. Figure~\ref{fig:smart_factory_case_study}~\textbf{D} shows the total learning energy required to master all 512 skills. While \ac{til}, the best conventional method, requires $2.5~\unit{\giga\J}$, the \acl{cl} paradigm achieves the same result using only $0.2~\unit{\giga\J}$. This represents a $90\%$ reduction in energy, or an order-of-magnitude improvement, validating our hypothesis and positioning \ac{cl} as a scalable and energetically sustainable solution for flexible manufacturing.

% ---
\begin{figure*}[t!]
	\centering
	\hspace*{\fill}
	\includegraphics[width=17cm]{collective_learning_and_skill_manifold_conceptualization.png}
	\hspace*{\fill}
    \caption{\label{fig:collective_learning_and_skill_manifold_conceptualization} 
    	\textbf{Collective learning dynamics over an unknown structured skill manifold.} 
    	(\textbf{A}) \ac{eai} agents learn and share knowledge across a structured---however, inherently unknown---skill manifold. (\textbf{C}) Three canonical \ac{cl} regimes: \textit{Destructive}, learning inhibited by poor communication; \textit{Compensating}, weak agents supported by strong network; and \textit{Ideal}---network of knowledge---, synergistic learning across agents and network.   
    }
\end{figure*}
% ---

% ===================================================================================================
\subsection{A dynamical model of collective skill acquisition}

To understand the mechanism behind the 10-fold energy saving, we developed a dynamical systems model of collective skill acquisition. We first formally define the agents in this system:

% ---
\begin{definition}\label{def:robot_collective}
    A robot \textbf{\collective} is a group of $N_\mathrm{r}$ \ac{eai} agents that explore a skill manifold $\mathcal{S}$. Each agent is equipped with \ac{ai} algorithms to leverage skill similarity to learn and store knowledge, as well as communication capabilities to exchange and integrate this knowledge with its peers.
\end{definition}
% ---

We posit that the ``skill universe'' containing $N_S$ skills that this \collective~explores is not uniform but possesses an inherent structure. Skills are naturally grouped into $N_\mathcal{K}$ clusters based on shared similarity, such as a cluster for ``insertion tasks'' and another for ``processing tasks'' (Fig.~\ref{fig:collective_learning_and_skill_manifold_conceptualization}~\textbf{A}). This underlying structure, which the robot \collective~navigates, is represented as a ``skill manifold.''

We modelled the ``to-be-learned knowledge'' $\bar{\sigma}_{i,j}$ for a specific skill $s_j$ by an \ac{eai} agent $i$ in a \collective~as the dynamical system in Eq.~\eqref{eq:collective_knowledge_dynamics}. The rate at which this remaining knowledge decreases is dependent on the number of successfully learned skills available to the agent $\kappa_{i,k}$ and governed by the interplay of a set of key parameters, including agent learning gain $\alpha_i$, the intra-cluster knowledge sharing gain $\eta_i$, inter-cluster similarity matrix $(\bm{B})_{j,l}=\beta_{j,l}$, and the inter-agent transfer gain matrix $(\bm{\Gamma})_{i,l} = \gamma_{i,l}$ that enables \acl{cl}. The full derivation of this model is detailed in the \nameref{sec:methods}.

% We model the ``to-be-learned knowledge'' ($\bar{\sigma}_{i,j}$) for a specific skill $j$ by an \ac{eai} agent $i$ in a \collective as a dynamical system $\dot{\bar{\sigma}}_{i,j} = f\left(\kappa_{i,k};\alpha_i,\eta_i,\bm{B}, \bm{\Gamma}\right)\bar{\sigma}_{i,j}$. The rate at which this remaining knowledge decreases is dependent on the number of successfully learned skills available to the agent ($\kappa_{i,k}$) and governed by the interplay of a set of key parameters, including agent learning gain ($\alpha_i$), the intra-cluster knowledge sharing gain $\eta_i$, inter-cluster similarity matrix ($\bm{B}$), and the inter-agent transfer gain matrix ($\bm{\Gamma}$) that enables \acl{cl}. The full derivation of this model is detailed in the \nameref{sec:methods} and Eq.~\eqref{eq:collective_knowledge_dynamics}.




% We model the ``to-be-learned knowledge'' ($\bar{\sigma}_{i,j}$) for a specific skill $j$ by an \ac{eai} agent $i$ in a \collective as a dynamical system 
% % ---
% \begin{equation*}
%     \dot{\bar{\sigma}}_{i,j} =
% 	-\left[f(\kappa_{i,k};\alpha_i,\eta_i,\beta_{j},N_\mathrm{r}) + h(\bar{\bm{\sigma}};\bm{B},\bm{\Gamma},N_\mathrm{r})\right] \bar{\sigma}_{i,j},
% \end{equation*}
% % ---
% \noindent with $\kappa$ being the number of successfully learned skills available to the agent. The rate at which this remaining knowledge decreases is governed by the interplay of a set of key parameters (see \nameref{sec:methods}). The \textbf{agent learning gain} $\alpha_i \sim \mathcal{U}(\alpha_{\text{min}},\alpha_{\text{max}}) \in \mathbb{R}_+$ captures the embodiment-dependent inherent ability of agent~$i$ to acquire knowledge about skill~$j$ in isolation; the learning gains across all agents are collected in the vector~$\bm{\alpha}$, with the range $[\alpha_{\text{min}}, \alpha_{\text{max}}]$ assumed to be narrow (according to Asm.~\ref{assumption:agent_similarity}). The \textbf{intra-cluster knowledge sharing gain} $\eta_i \sim \mathcal{N}(\bar{\eta},\eta_{\Sigma})$ quantifies how effectively agent~$i$ can reinforce a skill~$j$ through memory of related skills in the same cluster; the vector~$\bm{\eta}$ aggregates these gains across agents and models the efficient reuse of experience, such as accessing stored subskills $\zeta_k$ to support composite skills $s_{j,k}$. The structural similarity within the skill manifold is captured in the \textbf{inter-cluster similarity matrix} $\bm{B} \in \mathbb{R}^{N_\mathcal{K} \times N_\mathcal{K}}$; a corresponding vector~$\bm{\beta}_{ij}$ weighs the contribution of skills from other clusters in the agent’s local memory to the learning of a new skill~$j$. Finally, the \textbf{inter-agent transfer gains} $\gamma_{j,l} \sim \mathcal{N}(\bar{\gamma},\gamma_\Sigma)$, collected in the matrix~$\bm{\Gamma} \in \mathbb{R}^{N_\mathrm{r} \times N_\mathrm{r}}$, model the flow of knowledge between agents, accounting for embodiment differences, communication noise, and variation in prior experience. In addition to these four interaction terms, the model includes the intrinsic intelligence $\delta \in (0,\delta_{\text{max}}]$ of the system, controlling also the \textbf{exponential depletion rate} of initially available knowledge.

% ===================================================================================================
\subsection{Behavioral regimes of \acl{cl}}

% ---
\begin{figure*}[t!]
	\centering
	\hspace*{\fill}
	\includegraphics[width=14cm]{collective_learning_cases.png}
	\hspace*{\fill}
	\caption[] {\label{fig:collective_learning_cases} \textbf{Canonical regimes of a \acl{cl} system.} Robot collectives exhibit distinct behaviors depending on the mean values of $\eta$ and $\gamma$, affecting the total learning episodes (and thus energy) and success rate. Four principal regimes are identified: (\textbf{A}) destructive, (\textbf{B}) canceling, (\textbf{C}) ideal, and (\textbf{D}) compensating. (\textbf{E}) Collective size influences both learning efficiency and success.}
\end{figure*}
% ---

We used this model in a more general skill learning scenario---the particulars of this scenario are provided in the \nameref{sec:supplementary_materials} Sec.~\ref{sec:cl_scenarios_supplementaries}---to explore how system-level behavior emerges from the interplay between two key factors: the average quality of internal learning of the agents in the \collective~$\bar{\eta}$ and the average quality of the network's knowledge sharing capabilities (defined by $\bar{\gamma}$). This analysis revealed nine canonical learning regimes (Fig.~\ref{fig:collective_learning_cases}), which can be categorized into four principal behaviors.

Figure~\ref{fig:collective_learning_and_skill_manifold_conceptualization}~\textbf{B} illustrates three of these principal regimes. The ``Destructive Sharing Regime'' (Case 1/9) occurs when competent agents ($\bar{\eta} > 0$) are misled by faulty, corrupt, or misaligned collective interactions ($\bar{\gamma} < 0$). In this regime, despite possessing robust internal learning capabilities, agents are hindered by corrupt external knowledge that spreads rapidly, inhibiting learning and degrading system-wide performance.

Conversely, the ``Compensating Regime'' (Case 9/9) features agents with poor individual learning capabilities or high rates of forgetting ($\bar{\eta} < 0$) that are supported by a strong, reliable, and constructive \collective~($\bar{\gamma} > 0$). Here, the robust network compensates for individual shortcomings, successfully guiding the \collective~to learn all skills.

The ``Ideal Synergistic Regime'' (Case 3/9), which we term the \textit{Network of Knowledge}, emerges when both agent-level retention and network-level sharing are constructive ($\bar{\eta} > 0, \bar{\gamma} > 0$). In this state, individual and collective learning reinforce each other, achieving maximal efficiency, rapid skill acquisition, and minimal energy expenditure. This is the regime realized in our smart factory case study. Other regimes, such as Case 7 ($\bar{\eta} < 0, \bar{\gamma} < 0$), represent a total system collapse where both agents and the network actively destroy knowledge.

% ---
\begin{figure*}[t!]
	\centering
	\hspace*{\fill}
	\includegraphics[width=14cm]{cases_point_plot.png}
	\hspace*{\fill}
	\caption[] {\label{fig:cases_point_plot} \textbf{Collective size influences both learning efficiency and success.} The size of the robot collective can steer the learning of the skill universe, leveraging the positive influence of $\bar{\gamma}$.}
\end{figure*}
% ---

The size of the \collective~($N_\mathrm{r}$) has a profound and divergent influence on these dynamics (Fig.~\ref{fig:cases_point_plot}). In destructive regimes (for instance, Case 1), a larger \collective~is a liability; it amplifies the spread of corrupt knowledge, leading to a catastrophic collapse in the learning success rate (that is, the percentage of effectively learned skills). However, in compensating regimes (for example, Cases 8 and 9), a larger \collective~is the key to success. The redundancy and parallel knowledge exchange provided by more agents are necessary to overcome individual failures and drive the system toward a 100\% success rate. This demonstrates that in a \ac{cl} system, the health and structure of the inter-agent knowledge network are more critical to success than the isolated capabilities of any single agent.

One final aspect related to the size of the \collective~is the energy used for the continuous and concurrent inter-agent knowledge sharing. As the number of agents increases, the fraction of the learning energy required for communication scales quadratically with the number of robots (see \nameref{sec:supplementary_materials} Eq.~\eqref{eq:energy_per_episode}).

% ===================================================================================================
\subsection{Collective sharing overcomes knowledge partitioning}

% ---
\begin{figure*}[t!]
	\centering
	\hspace*{\fill}
	\includegraphics[width=16cm]{learning_paradigms_and_size_of_collective.png}
	\hspace*{\fill}
	\caption[] {\label{fig:learning_paradigms_and_size_of_collective} \textbf{Effect of the collective size on the total number of learning episodes.} {(\textbf{A}) In the classical paradigms, even when learning in parallel, each agent holds its own memory and can only access the subset of knowledge corresponding to the skills it has seen. This effectively splits the total knowledge. The more agents, the less available knowledge per agent. (\textbf{B}) The plot shows that as a result of having more agents, the classical paradigms degrade the learning and converge to \acl{isl}. On the contrary, \acl{cl} exploits the number of robots, exponentiating the learning as a result.}}
\end{figure*}
% ---

The superior scaling behavior seen in the smart factory case study is ultimately explained by the ability of \ac{cl} to overcome ``knowledge partitioning.''

In conventional paradigms (\ac{isl}, \ac{il}, \ac{til}), even when agents learn in parallel, they do not share their experiences. This effectively splits the total skill universe among the agents (Fig.~\ref{fig:learning_paradigms_and_size_of_collective}~\textbf{A}). As the number of robots ($N_\mathrm{r}$) in the \collective~increases, each agent learns a smaller fraction of the total skills.

This partitioning has a deeply detrimental effect on scalability. Because the pool of ``prior knowledge'' available in each agent's local memory shrinks, the power of \ac{il} and \ac{til} diminishes. An agent cannot leverage prior knowledge it does not have. As shown in Fig.~\ref{fig:learning_paradigms_and_size_of_collective}~\textbf{B}, this causes the performance of \ac{il} and \ac{til} to degrade as the \collective~size increases, eventually converging to the inefficient baseline of \ac{isl}. In these paradigms, scaling the workforce ($N_\mathrm{r}$) provides no synergistic benefit and, in fact, diminishes the effectiveness of advanced learning strategies.

\Acl{cl} fundamentally reverses this trend. Because knowledge is actively exchanged and integrated, adding more agents increases the rate of concurrent skill discovery and horizontal sharing. The total complexity of learning the entire skill universe decreases as $N_\mathrm{r}$ grows, because the shared knowledge base is exponentially enriched by the parallel exploration of all agents. This synergistic integration, where the collective knowledge becomes far greater than the sum of its parts, is the key mechanism that enables \ac{cl} to scale efficiently and sustainably, turning a larger \collective~from a scaling problem into a scaling solution.

% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
\section{Discussion}\label{sec:discussion}

% ===================================================================================================
\subsection{Synthesis of the findings}
This work establishes a principled foundation for understanding and optimizing energy efficiency in \ac{eai} systems through the lens of \acl{cl}. Our results validate our central hypothesis, demonstrating in a smart factory case study that \ac{cl} can master a complex skill universe using only about 10\% of the energy required by the best-performing conventional paradigm (Fig.~\ref{fig:smart_factory_case_study}~\textbf{D}). This order-of-magnitude improvement, which enables zero-shot learning for new products and virtually eliminates production downtime, is not a minor optimization but a fundamental shift in learning dynamics.

Our dynamical systems model provides the theoretical explanation for this emergent efficiency. The failure of conventional paradigms (\ac{isl}, \ac{il}, and \ac{til}) stems from ``knowledge partitioning'' (Fig.~\ref{fig:learning_paradigms_and_size_of_collective}). When agents learn in parallel but without inter-agent knowledge sharing, scaling the number of robots degrades, rather than enhances, advanced learning strategies. As the \collective's size increases, each agent's local memory---its pool of prior knowledge---shrinks, essentially forcing all agents to fall back to the default most basic, yet inefficient, learning form, \ac{isl}.

\Ac{cl} fundamentally reverses this trend. By enabling horizontal sharing of concurrent experiences and vertical transfer of prior knowledge, the \collective's knowledge base is enriched, not partitioned, by the addition of more agents. This synergistic integration allows the system to operate in the ``Ideal Synergistic Regime'' (Fig.~\ref{fig:collective_learning_cases}, Case 3). As our regime analysis showed, this constructive, network-level reinforcement is the key to scalable success. This efficiency derives directly from collective knowledge composition: distributed agents cooperatively integrate prior knowledge and concurrent experience to synthesize new capabilities, yielding exponential improvements in learning efficiency \cite{Haddadin2019Breakingwallcollective}.

% ===================================================================================================
\subsection{\Acl{cl} as a solution to the grand energy challenges}

% ---
\begin{figure}[!th]
	\centering
	\includegraphics[width=0.45\textwidth]{fig/grand_challenges_connections.png}
	\caption{\textbf{Interconnection between energy challenges C1, C2, and C3.}}
	\label{fig:challengesConnected}
\end{figure}
% ---

These findings position \ac{cl} as a practical lever for addressing the three grand energy challenges (Fig.~\ref{fig:challengesConnected}).

First, \ac{cl} directly addresses the \acl{cce} ($E_\mathrm{CCE}$) associated with \ac{c1}. In current practice, every robot repeatedly computes policies or retrains models in isolation, multiplying the demand for cloud resources and \ac{gpu} clusters. \Ac{cl} allows skill knowledge acquired by one agent to be stored, exchanged, and reused by others. Instead of thousands of redundant training runs, the \collective~can converge after a few representative experiences, shifting the resource profile from expensive parallel training toward lighter operations like querying and incremental updates, which drastically reduces \ac{gpu} hours \cite{Sekala2024SelectedIssuesMethods}.

Second, \ac{cl} mitigates the energetic footprint ($E_\mathrm{BBE}$ and $E_\mathrm{MIE}$) left by the proliferation of physical robots discussed in \ac{c2}. Learning through physical interaction is costly; each trial requires actuation, sensing, and interaction. In conventional paradigms, multiple robots execute the same task, consuming \acl{mie} in proportion to the \collective~size. With \ac{cl}, in principle, only a subset of robots needs to physically explore a skill; others can learn from their experience via continuous, concurrent, and structured knowledge sharing. As shown in our case study, this shortens the required trials per agent, lowering total learning energy and reducing production downtime.

Third, \ac{cl} indirectly addresses the manufacturing-related energy linked to \ac{c3}. This demand grows with the size of the \collective. By enabling better use of existing robots, \acl{cl} allows fleets to adapt to new tasks without costly hardware replacement. If robots learn faster, fewer redundant units are required to maintain productivity. Furthermore, by reducing retraining loads and unnecessary wear, \ac{cl} can extend the service life of robots and electronic components, lowering the frequency of new production cycles \cite{Ude2025Recycling}.

% ===================================================================================================
\subsection{Situating \acl{cl} in the broader landscape of \ac{ai}}
The procedural notions of \ac{il} and \ac{tl} can be can be revisited through a more integrative and structural lens. Traditionally, \ac{il} focuses on sequentially updating model parameters to avoid forgetting, while \ac{tl} reuses pre-trained representations across domains. However, in our modelling framework, these concepts are defined in terms of knowledge organization: \ac{il} corresponds to reuse within a cluster, where the learning efficiency scales with the number of acquired skills, and \ac{tl} represents reuse between clusters, governed by transferable fractions and a similarity matrix~$\bm{B}$. This structural view reframes learning as the continuous composition of knowledge within and across skill clusters, rather than as isolated updates to a single model. A comparative summary of these distinctions is
provided in Table~\ref{tab:IL_TL}.

Foundation models---spanning language, vision–language, and embodied domains---extend this idea on a global scale \cite{firoozi2025foundation}. While they are often described as exhibiting IL or TL through fine-tuning or prompting, their learning dynamics differ from the structured knowledge sharing dynamics we describe. Rather than performing direct skill transfer, they operate through large-scale pattern discovery across diverse representational spaces. Nonetheless, foundation models can provide powerful initial conditions for embodied and continual learning, offering broad priors that accelerate adaptation and skill refinement when coupled with reinforcement or experience-driven learning. By leveraging shared priors from, for example, foundation models and refining them through real-world interaction, \ac{cl} can transition learning from centralized pretraining toward \ac{slad}, opening a path for a more scalable and sustainable form of learning in \ac{eai}.

Within this broader landscape, \acl{cl} provides a complementary lens on distributed \ac{ai}. Whereas federated learning \cite{Technologie2023FLAIROPFederatedLearning,Anjos2023SurveyCollaborativeLearning,Xianjia2021Federatedlearningrobotic,Sartoretti2019DistributedLearningDecentralized,Wang2022DistributedReinforcementLearning} enhances data-efficient model training, and swarm intelligence \cite{Beni2004SwarmIntelligenceSwarm,Blum2015SwarmIntelligenceOptimization,Dorigo2021SwarmRoboticsPast} leverages emergent coordination for collective behavior, \ac{cl} focuses on the systematic propagation and integration of skill knowledge across interacting \ac{eai} agents. Related multi-agent learning systems \cite{busoniu2008comprehensive,zhang2021multi} have advanced coordinated decision-making and policy optimization—often supported by shared critics or policy distillation mechanisms \cite{lowe2017multi}—yet they typically do not target the structured accumulation of reusable skill components. In contrast, \ac{cl} enables agents to exchange and compose partial knowledge representations, reducing redundant exploration and accelerating collective skill acquisition. %In this way, multi-agent learning and \ac{cl} occupy complementary roles: the former coordinates behavior, while the latter coordinates the growth of knowledge within a \collective.



% ===================================================================================================
\subsection{Closing remarks}
Challenges arise in a landscape in which the energy demands of \ac{ai} and robotics continue to escalate, raising pressing questions about long-term sustainability \cite{Vinuesa2020roleartificialintelligence}. Addressing these concerns requires not only advances in mechanical and computational hardware but also more efficient ways of acquiring, sharing, and reusing knowledge across machines. As argued in \cite{Kaelbling2020foundationefficientrobot}, efficient robot learning must integrate sample efficiency, generalization, compositionality, and incremental learning—capabilities that naturally align with the \ac{cl} paradigm.

Our results highlight that conventional learning paradigms---such as isolated, incremental, or transfer learning---scale poorly as the number of \ac{eai} agents increases. Their inability to leverage already acquired knowledge efficiently leads to excessive learning energetic costs. In contrast, \ac{cl} takes advantage of skill similarity and structured inter-agent communication to improve performance as the \collective~grows, enabling the concurrent acquisition of multiple skills with reduced energy expenditure, even in heterogeneous robotic embodiments.

Realizing the full potential of the \ac{cl} paradigm, however, requires foundational advances in both algorithms and systems infrastructure, many of which are still under development or remain entirely open \cite{Haddadin2022collectivelearningtheory}. Our current validation is purely simulation-based, making controlled physical experiments essential for bridging the sim-to-real gap.

Transitioning to real-world deployments will further expose practical challenges associated with \ac{cl}. Differences in embodiment, communication inaccuracies, and synchronization failures will interact with broader limitations of today’s robotic environments. In most settings, the infrastructure required for large-scale \ac{cl} is lacking: communication networks offer limited bandwidth and exhibit non-negligible latency; high-bandwidth communication imposes substantial energy costs; and the large-scale computation needed for distributed learning is seldom available outside specialized data centers. These constraints fundamentally shape and restrict how a \collective~may operate.

Our regime analysis (Fig.~\ref{fig:collective_learning_cases}) shows that collective behavior is sensitive to the average inter-agent transfer gain ($\bar{\gamma}$). Without reliable communication channels and robust synchronization protocols, this sensitivity can push the system into undesirable regimes---such as ``Destructive Sharing'' or ``Compensating''---—thereby undermining the benefits of \ac{cl}. Overcoming these infrastructural barriers is therefore essential for safe and effective deployment.

In summary, the findings presented in this work position \ac{cl} as a compelling pathway toward scalable, adaptive, and energy-efficient \ac{eai} systems. While significant challenges remain, they also serve as a clear roadmap for future research. By advancing communication infrastructure, developing energy-aware protocols, and enabling accessible large-scale computation, we can move \ac{cl} from theory to robust, real-world deployments.

%—unlocking its full potential for the next generation of intelligent robotic systems.
% We must acknowledge that the foundational algorithms and infrastructure required to realize the \ac{cl} paradigm are either still in development or yet to be established \cite{Haddadin2022collectivelearningtheory}. Our validation is simulation-based, and a key next step is to bridge the sim-to-real gap with physical experiments.

% Such a deployment will introduce complex factors, including differences in embodiment, communication inaccuracies, and synchronization breaches. Our regime analysis (Fig.~\ref{fig:collective_learning_cases}) shows that system behavior is highly sensitive to the inter-agent transfer gain ($\bar{\gamma}$). This highlights the critical need for robust protocols to maintain knowledge integrity and prevent the system from falling into ``Destructive Sharing'' or ``Compensating'' regimes. Furthermore, a full-scale deployment must account for the energy overhead of communication itself, a factor that requires further study in real-world network architectures.

% Despite remarkable progress in \ac{ai} and robotics, their rapid expansion has led to escalating energy demands that challenge their long-term sustainability \cite{Vinuesa2020roleartificialintelligence}. Addressing this issue requires not only advances in computing and mechanical hardware but also a paradigm shift in how knowledge is collected, shared, and reused across intelligent systems. As discussed in \cite{Kaelbling2020foundationefficientrobot}, efficient robotic learning must combine sample efficiency, generalizability, compositionality, and incremental learning---capabilities that are naturally supported by the \acl{cl} paradigm. By enabling real-time, distributed knowledge exchange among networked embodied agents, \ac{cl} promotes both energy- and time-efficient skill acquisition.

% Our results show that conventional paradigms---such as isolated incremental or transfer learning, including those underlying current foundation models---scale poorly with the number of embodied or distributed agents, leading to inefficient energy utilization. In contrast, \ac{cl} leverages skill similarity and inter-agent communication to achieve superior performance as the \collective~grows in size, facilitating the concurrent learning of multiple skills with reduced energy expenditure. By fostering continuous, cooperative learning across both embodied and distributed agents, \ac{cl} offers a powerful framework for advancing energy-efficient, scalable, and adaptive \ac{ai} systems.

% We must acknowledge that the foundational algorithms and systems infrastructure required to fully realize the \ac{cl} paradigm are still emerging, and in many cases remain undeveloped \cite{Haddadin2022collectivelearningtheory}. Our validation is currently simulation-based, and a key next step is to bridge the sim-to-real gap through controlled physical experiments.

% A real-world deployment will introduce additional layers of complexity. Differences in embodiment, communication inaccuracies, and synchronization breaches will interact with more fundamental limitations of today’s cyber-physical infrastructure. In particular, most robotic environments lack the networking backbone needed for scalable \acl{cl}: communication links often exhibit non-negligible latency, bandwidth is limited and unevenly available, and on-site compute is typically insufficient for large-scale distributed training. Our regime analysis (Fig.~\ref{fig:collective_learning_cases}) shows that system behavior is highly sensitive to the inter-agent transfer gain ($\bm{\Gamma}$). This sensitivity underscores the need for communication protocols that maintain knowledge integrity even under constrained or unreliable networking conditions, and that prevent the system from drifting into ``Destructive Sharing'' or ``Compensating'' regimes. Moreover, a full-scale deployment must explicitly account for the energy overhead associated with high-bandwidth communication itself---an aspect that remains understudied, yet may signify a non-negligible share of the energy budget in real-world network architectures.

% Despite remarkable progress in \ac{ai} and robotics, their rapid growth has produced escalating energy demands that threaten long-term sustainability \cite{Vinuesa2020roleartificialintelligence}. Meeting this challenge requires more than advances in hardware; it requires a fundamental shift in how knowledge is collected, shared, and reused across intelligent systems. As argued in \cite{Kaelbling2020foundationefficientrobot}, efficient robotic learning must combine sample efficiency, generalizability, compositionality, and incremental skill acquisition—capabilities that are naturally aligned with the \ac{cl} paradigm. By enabling real-time, distributed knowledge exchange among networked embodied agents, \ac{cl} can promote both energy- and time-efficient learning.

% Our results indicate that conventional paradigms—such as isolated incremental learning or transfer learning, including those underlying today’s foundation models—scale poorly as the number of embodied or distributed agents increases, leading to inefficient use of energy and compute. In contrast, \ac{cl} exploits skill similarity and inter-agent communication to achieve superior performance as the \collective~grows. This coordination facilitates the concurrent acquisition of multiple skills with reduced energy expenditure, even under heterogeneous embodiments. By fostering continuous, cooperative learning across both embodied and distributed agents, \ac{cl} offers a promising pathway toward scalable, adaptive, and energy-efficient \ac{ai} systems-provided that future work confronts the infrastructural challenges of communication latency, bandwidth constraints, and the current lack of accessible large-scale computation infrastructure for learning.

% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
\section{Methods}\label{sec:methods}
We consider a skill-learning scenario defined as the tuple
% ---
\begin{equation}
	\phi = \left(N_\mathcal{S}, N_\mathcal{K}, N_\mathrm{r}, \bm{\rho} \right) \in \Phi,
\end{equation}
% ---
where $N_\mathcal{S}$ is the total number of skills to learn, $N_\mathcal{K}$ is the number of skill clusters, $N_\mathrm{r}$ is the number of \ac{eai} agents, i.e., the size of the \collective, and $\Phi$ represents the set of all possible viable combinations. The parameter tuple
% ---
\begin{equation}
	\bm{\rho} = \left(\bm{\alpha}, \bm{B}, \delta, \bm{\eta},\bm{\Gamma}\right),
\end{equation}
% ---
defines the knowledge exchange efficiency of the particular scenario; depicted in Fig.~\ref{fig:collective_learning_and_skill_manifold_conceptualization}. Notice that the generality of $\Phi$ makes it representative of a variety of situations. A skill-learning scenario may involve a smart factory where numerous robots learn distinct manufacturing skills, a domestic environment in which service robots acquire different household skills, a team of underwater robots performing exploration, inspection, and maintenance operations, or a fleet of autonomous vehicles executing logistics and delivery missions.

% ===================================================================================================
\subsection{Modeling skill knowledge acquisition dynamics}\label{sec:knowledge_dynamics_model}
% ---
\begin{table}[ht]
    \centering
    \scriptsize % reduces font size to ~10 pt
    \renewcommand{\arraystretch}{1.3}
    \caption{Core modelling assumptions of the \acl{cl} model.\label{tab:modeling_assumptions}}
    %\captionsetup{skip=1pt}
    \begin{center}
        %\begin{adjustbox}{width=\textwidth}
            \begin{tabular}{
                *{1}{>{\raggedright\arraybackslash}p{16cm}}
            }            
                \toprule
                \begin{minipage}[t]{\linewidth}\vspace{0pt}
                \begin{assumption}\label{assumption:power_and_episode_time}
                %The average behavior of a system with large $N_\mathrm{r}$ and $N_S$ can be described by an average power $P_0$ and mean episode time $\Delta t$, with both being approximately constant.
                % The average energy consumption of a trial learning episode $e_0$ is constant if inter-agent communication is unexistent otherwise it scales with the number of agents 
                % $N_\mathrm{r}$, that is, $e_0(N_\mathrm{r})$.
                The average energy consumption of a trial learning episode $e0$ is constant when agents do not communicate, but grows with the size of the \collective~$N_\mathrm{r}$ once inter-agent communication is enabled.
                \end{assumption}\vspace{-5pt}
                \end{minipage}\\
                \begin{minipage}[t]{\linewidth}\vspace{0pt}
                \begin{assumption}\label{assumption:skill_clustering}
                Significant similarity among a set of skills accelerates the overall learning process due to the exchange of acquired knowledge from these skills.
                \end{assumption}
                \end{minipage}\\
                \begin{minipage}[t]{\linewidth}\vspace{0pt}
                \begin{assumption}\label{assumption:exponential_decrease}
                The remaining knowledge function $\bar{\sigma}_{i,j}(\cdot)$ has strictly monotonically decreasing behavior.
                \end{assumption}
                \end{minipage}\\
                \begin{minipage}[t]{\linewidth}\vspace{0pt}
                \begin{assumption}\label{assumption:average_behavior}
                The system exhibits an average behavior resulting from comparable agents learning skills that are ordered and segregated according to their similarity.
                \end{assumption}
                \end{minipage}\\
                \begin{minipage}[t]{\linewidth}\vspace{0pt}
                \begin{assumption}\label{assumption:agent_similarity}
                Each \ac{eai} agent in the system has the same capabilities, with highly similar \ac{bbe} and \ac{mie} expenditures.
                \end{assumption}
                \end{minipage}\\
                \begin{minipage}[t]{\linewidth}\vspace{0pt}
                \begin{assumption}\label{assumption:cluster_size}
                The large number of skills in $\mathcal{S}$ implies that every cluster $\mathcal{Z}_k$ contains the same number $N_{\mathcal{Z}}$ of skills.
                \end{assumption}
                \end{minipage}\\
                \begin{minipage}[t]{\linewidth}\vspace{0pt}
                \begin{assumption}\label{assumption:cluster_transferability}
                Knowledge transferability between in-cluster skills is equal, as is transferability between clusters.
                \end{assumption}
                \end{minipage}\\
                \begin{minipage}[t]{\linewidth}\vspace{0pt}
                \begin{assumption}\label{assumption:enabling_agorithms}
                Advanced control and learning algorithms are readily available to inherently use the shared knowledge.
                \end{assumption}
                \end{minipage}\\
                
                \bottomrule
            \end{tabular}
        %\end{adjustbox}
    \end{center}
\end{table}
% ---

The modelling of the knowledge acquisition dynamics of the \collective~under different learning paradigms is built on a set of simplifying assumptions summarized in Table~\ref{tab:modeling_assumptions}. These assumptions toghether serve to define the boundaries and focus of our analysis.

Understanding the energy and time demands represented by a team of $N_\mathrm{r}$ robots learning a skill universe $\mathcal{S}=\left\lbrace s_1,s_2,\ldots s_j,\ldots, s_{N_\mathcal{S}}\right\rbrace$, requires analizing how skill knowledge is gained and what effect it may have on the acquisition of any new skill knowledge. 

We refer to the \emph{complexity} $c_j$ of skill $ s_j $ as the number of trial episodes $n$ required to successfully learn it, namely, all actions and states visited by an \ac{eai} agent until a predefined stopping criterion is reached. As a consequence of Asm.~\ref{assumption:power_and_episode_time}, given the---fixed---energetic cost 
%\end{equation}
\begin{equation}\label{eq:energy_per_learning_episode}
	e_0(N_\mathrm{r},\lambda) = E_\mathrm{BBE} + E_\mathrm{MIE} + E_\mathrm{CCE}(N_\mathrm{r},\lambda),
\end{equation}
% ---
\noindent for a trial episode, the learning energy $E_j$ expended by an \ac{eai} agent to master $s_j$ is directly proportional to its complexity. By extension, taking $C_\mathcal{S}$ as the total trial episodes to learn all $N_\mathcal{S}$ skills, then the total learning energy is simply $ E_\mathcal{S} \propto C_\mathcal{S} \: e_0$ (see \nameref{sec:supplementary_materials} Sec.~\ref{sec:energy_time_and_power_per_episode}).

% , and according to Eqs.~\eqref{eq:energy_per_episode},~\eqref{eq:energy_per_episode},\eqref{eq:energy_per_skill}, and \eqref{eq:total_energy} in Sec.~\ref{sec:energy_time_and_power_per_episode}, the energy demand of an \ac{eai} agent learning a skill (or set of skills) is in first-order directly proportional to the skill(s) complexity.


%     E_\mathrm{total} \propto C_\mathrm{total} \: e_0(N_\mathrm{r},\lambda)


% As a consequence of Asm.~\ref{assumption:power_and_episode_time} (see Fig.~\ref{fig:power_per_episode}), and according to Eqs.~\eqref{eq:energy_per_episode},~\eqref{eq:energy_per_episode},\eqref{eq:energy_per_skill}, and \eqref{eq:total_energy} in Sec.~\ref{sec:energy_time_and_power_per_episode}, the energy demand of an \ac{eai} agent learning a skill (or set of skills) is in first-order directly proportional to the skill(s) complexity.

Let $\mathcal{Z}_k \subset \mathcal{S}$ be a subset of $N_{\mathcal{Z}_k}$ highly similar skills; that is, a \emph{cluster} of similar skills, see Fig.~\ref{fig:collective_learning_and_skill_manifold_conceptualization}~\textbf{A} and  Fig.~\ref{fig:skill_similarity_and_knowledge}~\textbf{A}. Furthermore, consider a second set $\mathcal{\zeta}_k \subset \mathcal{Z}_k$ that denotes the skills from $\mathcal{Z}_k$ that a given agent $i$ has already learned. Asm.~\ref{assumption:skill_clustering} implies that if $s_{j} \in \mathcal{Z}_k$, then agent $i$ can improve the learning of the skill benefiting from the knowledge contained in $\mathcal{\zeta}_k$. Consequently, the more skills in $\mathcal{\zeta}_k$, the less knowledge about $ s_{j} $ remains to be learned. To model this effect, we introduce the to-be-learned knowledge function $\bar{\sigma}_{i,j}\left(n\right)\in [0,1]$ expressing the knowledge about a skill $s_{j} \in \mathcal{Z}_k \setminus \mathcal{\zeta}_k$ that \emph{is not yet} contained in the knowledge base $\mathcal{\zeta}_k$. The function $\bar{\sigma}_{i,j}(\cdot)$ satisfies
% ---
\begin{equation}\label{eq:sigma_bar_conditions}
	\bar{\sigma}_{i,j}\left(n\right) = 
	\begin{cases}
		1 & \text{$\mathcal{\zeta}_k=\emptyset$},\\
		0 &\text{$\mathcal{\zeta}_k$ has \emph{all} knowledge of $s_{j}$}.
	\end{cases}
\end{equation}
% ---
Conceptually, $\bar{\sigma}_ {i,j}\left(\cdot\right)$ is the fraction of knowledge from ${\mathcal{Z}_k}$ that remains to be learned.

% ---
\begin{figure}[!t]
	\centering
	\includegraphics[width=0.95\textwidth]{fig/skill_similarity_and_knowledge.png}
	\caption{\textbf{Skill similarity and knowledge.} (\textbf{A}) Skills in $\mathcal{S}$ inherently group into clusters $\mathcal{Z}_k$ based on their similarity, (\textbf{B}) the remaining knowledge $\bar{\sigma}_{i,j}$ to learn a new skill $s_{j}$ has strictly monotonically decreasing behavior.}
    \label{fig:skill_similarity_and_knowledge} 
\end{figure}
% ---

To evaluate the effect of knowledge exchange during learning on the complexity of mastering a skill, we introduce a hypothetical upper bound called the skill \textit{fundamental complexity} $c_0$, which describes the maximum number of trial episodes required to learn \emph{any} skill. If, in learning a skill $ s_{j} $, the $i$-th \ac{eai} agent accesses and uses its knowledge contained in $\mathcal{\zeta}_k$, then two effects occur:
% ---
\begin{enumerate}
	\item There is less remaining knowledge, reflected in the initial value; i.e., $\bar{\sigma}_{i,j}(0) < 1$
	\item The knowledge acquisition rate increases. Equivalently, this may also be interpreted as an increase in the depletion rate of the remaining knowledge.
\end{enumerate}
% ---
These effects signify that the remaining knowledge scales down as a function of the number $N_{\zeta_k}=|\mathcal{\zeta}_k|$ of skills an agent has already learned. Consequently, the complexity $c_{j}$ of said skill is smaller than the fundamental complexity $c_0$. An idealization of the behavior satisfying Asm.~\ref{assumption:exponential_decrease} and Eq.~\eqref{eq:sigma_bar_conditions} can be modeled by a dynamical system depending on the trial episodes $n$ and parameterized by the number of already learned skills $N_{\zeta_k}$. As such,
% ---
\begin{definition}\label{assumption:ode_model} the remaining knowledge function $\bar{\sigma}_{i,j}$ is modeled as the first order dynamical system
	\begin{equation}\label{eq:simple_knowledge_dynamics}
		\dot{\bar{\sigma}}_{i,j}\left(n\right)=\begin{cases}
			-f_{i,j} \left(N_{\zeta_k} \right) \bar{\sigma}_{i,j}\left(n\right), & \epsilon < \bar{\sigma}_{i,j}\left(n\right) < 1, \\
			0, & \text{otherwise}.
		\end{cases}
	\end{equation}	
\end{definition}
% * NOTE: the subindex j,k means skill j in cluster k
% ---
\noindent Considering its initial condition as $\bar{\sigma}_{i,j}(0) =  g_{i,j} \left(N_{\zeta_k}\right)$, the corresponding solution
% ---
\begin{equation}\label{eq:knowledge_exponential_form}
	\bar{\sigma}_{i,j}(n) = g_{i,j}(N_{\zeta_k}) e ^{-f_{i,j}\left(N_{\zeta_k}\right) n} \in (0,1],
\end{equation}
% ---
exhibits the desired behavior, shown in Fig.~\ref{fig:skill_similarity_and_knowledge}~\textbf{B}. The function $f_{i,j}\left(N_{\zeta_k}\right)$ models one of the effects resulting from the exploitation of the knowledge available in $\zeta_k$, namely, the increase of the learning rate. The second effect, namely, the reduction in the initial remaining knowledge $\bar{\sigma}_{i,j}(0)$ is controlled by the term $g_{i,j}\left(N_{\zeta_k}\right)$, which is also dependent on the number of learned skills. The learning threshold $\epsilon$---depicted as the green-shaded area---indicates when the remaining knowledge is negligible and $s_{j}$ is considered to have been learned. Consequently, the number of trial episodes until $\bar{\sigma}_{i,j}<\epsilon$ denotes the corresponding skill complexity $c_j$.

% ---
\begin{figure}[!t]
	\centering
	\includegraphics[width=0.95\textwidth]{fig/learning_paradigms_conceptual_figure.png}
	\caption{\label{fig:learning_paradigms_conceptual_figure} \textbf{The different learning paradigms.} (\textbf{A}) \Acl{il} benefits from the significant similarity of skills belonging to the same cluster. (\textbf{B}) In \acl{tl}, knowledge is shared from various source clusters to a target cluster. Notice that using many robots (e.g., two robots $r_1$ and $r_2$) without inter-agent knowledge exchange among them only subdivides the problem. (\textbf{C}) Exchange of knowledge between \ac{eai} agents enables \acl{cl}.}
\end{figure}
% ---

% ===================================================================================================
% \paragraph*{Knowledge sharing under different learning paradigms}
\subsection{Knowledge sharing under different learning paradigms}
When an \ac{eai} agent learns in isolation---that is, performs \ac{isl}---it learns every skill from the ground up, disregarding knowledge from already learned skills. In contrast, during \ac{il}---also known as continual learning \cite{Lesort2020Continuallearningrobotics}---an agent benefits from the continuous exchange and integration of knowledge from \emph{intra-cluster} skills in virtue of their significant similarity. As depicted in Fig.~\ref{fig:learning_paradigms_conceptual_figure}~\textbf{A}, a robot ($r_1$ in this case) learns every skill in $\mathcal{Z}_1$ with a rate $\alpha$---the self-learning loops---but also retains the acquired knowledge in its local memory and uses it to learn subsequent skills. \Ac{tl} alone refers to the use of acquired knowledge about a distant set of skills on a new skill \cite{Hosna2022Transferlearningfriendly,Jaquier2023TransferLearningRobotics}. In particular, it implies the one-time \emph{inter-cluster} exchange of knowledge. \Ac{tl} represents the exchange of knowledge from the skills learned in different \emph{origin} clusters $\mathcal{O} = \{ \mathcal{Z}_1,\mathcal{Z}_2,\ldots,\mathcal{Z}_{k-1} \}$ to the skills that will be learned in a \emph{destination} cluster $\mathcal{Z}_k$ (see Fig.~\ref{fig:learning_paradigms_conceptual_figure}~\textbf{B}). Concretely, the effect that \ac{tl} has on the skills of the destination cluster is the reduction of the initial remaining knowledge and the increase of the initial learning rate for all the skills in the target cluster through \emph{transferable knowledge fraction factor} $\xi_k \in [0,1)$. The latter results from accounting for the available knowledge $\varsigma^{(k)}$ that an agent has in memory about each of the $N_\mathcal{K}$ clusters weighted by the \emph{cluster similarity matrix}
% ---
\begin{equation}\label{eq:cluster_similarity_matrix}
	\bm{B}\in \mathbb{R}^{N_\mathcal{K} \times N_\mathcal{K}}=\begin{cases}
		1, & i=j, \\
		\beta_{i,j} = \beta_{j,i}, & i \neq j.
	\end{cases}
\end{equation}
% ---
Here, $\beta_{i,j} \in [0,1)$ defines the closeness between the skills in the different clusters (recall the dashed lines in  Fig.~\ref{fig:collective_learning_and_skill_manifold_conceptualization}~\textbf{A}). In general, \ac{il} and \ac{tl} are ideally combined; as such, we consider \ac{til} as the third learning paradigm. A complementary discussion about the effects of these paradigms on the skill complexity is provided in the \nameref{sec:supplementary_materials} Sec.~\ref{sec:conventional_learning_paradigms}.



% Details on the mathematical formalization of these paradigms are provided in \nameref{sec:methods} and further illustrated in the \nameref{sec:supplementary_materials} (Sec.~\ref{sec:conventional_learning_paradigms}).
% ===================================================================================================
% \paragraph*{\textbf{\Acl{cl}}}
\subsection{\textbf{\Acl{cl}}}
This paradigm goes far beyond simple parallelization, understood as learning different skills with different robots at the same time. In \ac{cl} $N_\mathrm{r}$ robotic agents $ \left\lbrace r_i \right\rbrace_{i=1}^{N_\mathrm{r}} $ develop and accumulate an emerging common mind (body of knowledge) dynamically via networked interactions where individual experience, knowledge, and skills are disseminated to all the other elements in the \collective~\cite{Garavan2012CollectiveLearning}. Information flows vertically as previous knowledge is passed on, automatically improving knowledge gaps in the skill tree, and horizontally by sharing concurrent experience between agents, to accelerate skill acquisition ``in action''. Knowledge can be replicated, complemented, and further developed via these mechanisms. Moreover, to enable \ac{cl} from a technical standpoint, it is assumed that an inter-agent communication protocol and the appropriate infrastructure are in place that allow agents to concurrently exchange and integrate the self-acquired and incoming knowledge to incrementally speed up the learning of all the agents as a whole. As a result, concurrent intra- and inter-cluster knowledge sharing is possible. Naturally, a complex scheduling problem to determine the optimal skill distribution and inter-agent knowledge-sharing strategy is part of the \ac{cl} paradigm. 

Rather than focusing on specific learning, communication, and scheduling algorithms to make \ac{cl} possible, our primary objective is to illustrate the overarching ideal systemic behavior of a group of robots performing \acl{cl}.~% system (see Fig.~\ref{fig:collective_learning_system}).
Grounded on Assumptions~\ref{assumption:average_behavior}, \ref{assumption:agent_similarity},~\ref{assumption:cluster_size}, and~\ref{assumption:cluster_transferability}, in the remainder of this work, we concentrate the discussion on the target knowledge-sharing dynamics of a \ac{cl} system. Figure~\ref{fig:learning_paradigms_conceptual_figure}~\textbf{C} illustrates the \ac{cl} concept, where the self-loop represents the knowledge dynamics of a single robot learning at a rate $\alpha$. The exchange of knowledge across agents is represented via the cross-couplings, weighted by a parameter $\gamma$ that models how efficient the bidirectional pairwise knowledge exchange is between any two agents. Similar to \ac{tl}, if two robots exchange knowledge about skills in different clusters $j$ and $l$, then $\gamma_{j,l}$ is scaled down by the cluster similarity $\beta_{j,l}$. 

In \ac{cl}, the dynamics of the remaining knowledge  about a skill acquired by an agent exchanging knowledge with a set $\mathcal{N}$ of other agents is described by
% ---
\begin{equation}\label{eq:collective_knowledge_dynamics}
	\dot{\bar{\sigma}}^{(\text{CL})}_{i,j} =
		\overbrace{\left[-\alpha_i\:\left( \frac{\eta_i \kappa + 1}{1 - \xi_{i,j}(\bm{B},\bm{\varsigma}_i)} \right)  - \sum\limits_{l \in \mathcal{N}(j)} \bar{\xi}_{i,l}(\bm{B},\bm{v}) \gamma_{i,l} d(\bar{\sigma}_{i,j},\bar{\sigma}_{l,\cdot})\right]}^{\textbf{learning rate}} \bar{\sigma}^{(\text{CL})}_{i,j},
\end{equation}
% ---
\noindent for $\epsilon < \bar{\sigma}_{i,j} < 1$ and with \textbf{initial condition} $\bar{\sigma}^{(\text{CL})}_{i,j}(0) = g_{i,j}\left(\kappa\right)$. Note that $\kappa$ represents the total number of successfully learned skills. Without knowledge sharing, $\kappa= N_{\zeta_k}$, with $N_{\zeta_k}$ being the number of skills already learned in the cluster of skill $s_j$. In \ac{cl}, ideally $\kappa$ is equal to all the skills learned by the robots in the \collective~up to the current learning cycle. However, it is possible that some agents may fail to successfully learn a given skill.

Each gain $\gamma_{i,l} \in \mathbb{R} $ in Eq.\eqref{eq:collective_knowledge_dynamics} weighs the knowledge exchange strength among robots. Together they make the hollow symmetric matrix $(\bm{\Gamma})_{i,l}=\gamma_{i,l}$ which also defines the connectivity of the \collective; i.e., a weighted adjacency matrix. Since robots may have in-memory skills from different clusters, the transferable knowledge fraction factor is given by
% ---
\begin{equation}\label{eq:scaled_transferable_knowledge_fraction}
	{\xi}_{i,j} = \mathbb{1}^\intercal_j\:(\bm{B} - \bm{I})\:\bm{\varsigma}_i ,
\end{equation}
% ---
\noindent~where $\mathbb{1}_j \in \mathbb{R}^{N_\mathcal{K}}$ is a one-hot vector representing the cluster to which skill $s_j$ belongs. In the absence of knowledge sharing, the entries of vector $\bm{\varsigma}_i \in \mathbb{R}^{N_\mathcal{K}}$ are the knowledge fraction from each skill cluster that agent $i$ holds in memory. In contrast, when operating as a \collective, $\bm{\varsigma}_i$ contains the aggregated cluster knowledge fraction gathered by all the agents. The expression in Eq.~\eqref{eq:scaled_transferable_knowledge_fraction} accounts for the one-time transfer of knowledge based upon the cluster similarity at the beginning of a learning cycle. Similarly, the term $ \bar{\xi}_{i,l}(\bm{B},\bm{v}) $ downsizes the concurrent---that is, during learning---sharing of knowledge coming from the skills currently being learned in different clusters. The vector $\bm{v} \in \mathbb{R}^{N_\mathrm{r}}$ describes the cluster membership of each of the skills in the current skill batch learned by the $N_\mathrm{r}$ agents. 

The \emph{knowledge integration function} 
% ---
\begin{equation}\label{eq:knowledge_integration_function}
	d(\bar{\sigma}_{i,j},\bar{\sigma}_{l,\cdot}) = e^{-a\:\left(\bar{\sigma}_{l,\cdot}-\bar{\sigma}_{i,j}\right)^2}\in [0,1],
\end{equation}
% --- 
\noindent in Eq.~\eqref{eq:collective_knowledge_dynamics} accounts for the contribution of knowledge from other agents, weighing it according to the relevance (similarity) of the shared knowledge. 

The resulting closed-form expressions for all the considered learning paradigms in this work, summarized in Table~\ref{tab:learning_paradigms_expressions}, provide a direct analytical basis to quantify and contrast their efficiency.

% ---
\begin{table}[!t]
    \caption{The dynamics of the remaining knowledge for the considered learning paradigms.\label{tab:learning_paradigms_expressions}}
    \begin{center}
        \begin{adjustbox}{width=\textwidth}
            \begin{tabular}{
                >{\raggedright\arraybackslash}p{3cm} 
                *{3}{>{\centering\arraybackslash}p{3cm}}
                *{1}{>{\centering\arraybackslash}p{6.5cm}}
            }            
                \toprule
                \textbf{Learning Paradigm} 
                & \textbf{\ac{isl}} 
                & \textbf{\ac{il}} 
                & \textbf{\ac{til}} 
                & \textbf{\ac{cl}} \\
                \midrule
                Learning rate 
                & $-\alpha_i$ 
                & $-\alpha_i\:\left(\eta_i \kappa + 1 \right)$ 
                & $-\alpha_i\:\left( \frac{\eta_i \kappa + 1}{1 - \xi_{i,j}(\cdot)} \right)$ 
                & $-\alpha_i\:\left( \frac{\eta_i \kappa + 1}{1 - \xi_{i,j}(\cdot)} \right) - \sum_{l \in \mathcal{N}(j)}\bar{\xi}_{i,l}(\cdot)\gamma_{i,l}d(\cdot)$ \\
                \addlinespace[0.5ex]
                Initial condition 
                & $1$ 
                & $e^{-\delta \kappa}$ 
                & $\left(1-\xi_{i,j}(\cdot)\right)\: e^{-\delta \kappa}$ 
                & $\left(1-\xi_{i,j}(\cdot)\right)\: e^{-\delta \kappa}$ \\
                \bottomrule
            \end{tabular}
        \end{adjustbox}
    \end{center}
\end{table}
% ---

% ===================================================================================================
\subsection{Summary of the model parameters}
Parameter $\kappa$ is the \textbf{number of successfully learned skills} available to the agent. The \textbf{agent learning gain} $\alpha_i \sim \mathcal{U}(\alpha_{\text{min}},\alpha_{\text{max}}) \in \mathbb{R}_+$ captures the embodiment-dependent inherent ability of agent~$i$ to acquire knowledge about skill~$j$ in isolation; the learning gains across all agents are collected in the vector~$\bm{\alpha}$, with the range $[\alpha_{\text{min}}, \alpha_{\text{max}}]$ assumed to be narrow (according to Asm.~\ref{assumption:agent_similarity}). The \textbf{intra-cluster knowledge sharing gain} $\eta_i \sim \mathcal{N}(\bar{\eta},\eta_{\Sigma})$ quantifies how effectively agent~$i$ can reinforce a skill~$j$ through memory of related skills in the same cluster; the vector~$\bm{\eta}$ aggregates these gains across agents and models the efficient reuse of experience, such as accessing stored subskills $\zeta_k$ to support composite skills $s_{j,k}$. The structural similarity within the skill manifold is captured in the \textbf{inter-cluster similarity matrix} $\bm{B} \in \mathbb{R}^{N_\mathcal{K} \times N_\mathcal{K}}$; a corresponding vector~$\bm{\beta}_{ij}$ weighs the contribution of skills from other clusters in the agent’s local memory to the learning of a new skill~$j$. Finally, the \textbf{inter-agent transfer gains} $\gamma_{j,l} \sim \mathcal{N}(\bar{\gamma},\gamma_\Sigma)$, collected in the matrix~$\bm{\Gamma} \in \mathbb{R}^{N_\mathrm{r} \times N_\mathrm{r}}$, model the flow of knowledge between agents, accounting for embodiment differences, communication noise, and variation in prior experience. In addition to these four interaction terms, the model includes the intrinsic intelligence $\delta \in (0,\delta_{\text{max}}]$ of the system, controlling also the \textbf{exponential depletion rate} of initially available knowledge.

% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
% \section{Methods}

% \subsection{Modeling Skill Knowledge Acquisition Dynamics}
% To model the acquisition of a skill $s_j$ (belonging to cluster $\mathcal{Z}_k$) by an \ac{eai} agent $i$, we define the ``to-be-learned knowledge'' function $\bar{\sigma}_{i,j}(n) \in [0, 1]$ as the fraction of knowledge that remains to be learned after $n$ trial episodes. The function satisfies $\bar{\sigma}_{i,j} = 1$ if no knowledge exists (learning from scratch) and $\bar{\sigma}_{i,j} = 0$ when the skill is fully mastered. 

% We model this process as a first-order dynamical system:
% \begin{equation}
%  \dot{\overline{\sigma}}_{i,j}(n) = \begin{cases} -f_{i,j}(\cdot) \overline{\sigma}_{i,j}(n), & \epsilon < \overline{\sigma}_{i,j}(n) \le 1 \\ 0, & \text{otherwise} \end{cases}   
% \end{equation}
% \noindent The solution to this is $\bar{\sigma}_{i,j}(n) = g_{i,j}(\cdot) e^{-f_{i,j}(\cdot)n}$, where the learning rate $f_{i,j}(\cdot)$ and the initial knowledge $g_{i,j}(\cdot)$ are functions that depend on the learning paradigm (\ac{isl}, \ac{il}, \ac{til}, or \ac{cl}). A skill is considered ``learned'' when its remaining knowledge drops below a threshold $\epsilon$.


% \subsubsection{Core System-Level Assumptions}
% A primary implication of these assumptions is the justification of a simplified, average-case dynamical model (Asm.~\ref{assumption:average_behavior}), which is made tractable by positing comparable agent capabilities (Asm.~\ref{assumption:agent_similarity}) and a balanced, structurally consistent skill manifold (Asm.~\ref{assumption:cluster_size} and \ref{assumption:cluster_transferability}). This structured approach is what allows for a quantifiable link between the number of learning episodes and the total energy cost (Asm.~\ref{assumption:power_and_episode_time}), providing a clear metric for efficiency. Fundamental to our modeling is that skill similarity drives accelerated learning (Asm.~\ref{assumption:skill_clustering}) and that this process is inherently stable and convergent (Asm.~\ref{assumption:exponential_decrease}). Crucially, Asm.~\ref{assumption:enabling_agorithms} establishes a key methodological boundary: it allows us to model the dynamics and analyze the learning regimes, while explicitly separating this from the practical implementation of the specific control and learning algorithms, which is considered for future work.


% \subsection{Learning Paradigm Models}
% Based on our modelling assumptions, we define the learning rate $f_{i,j}$ and initial condition $g_{i,j}$ for each paradigm in Table~\ref{tab:learning_paradigms_expressions}. \textbf{\Acl{isl}:} The agent learns every skill from scratch. Knowledge from previously learned skills is disregarded. \textbf{\Acl{il}:} The agent benefits from knowledge of $\kappa$ previously learned skills within the same cluster. Here, $\alpha_i$ is the agent's base learning gain, $\eta_i$ is the intra-agent knowledge gain, and $\delta$ is the knowledge depletion rate. \textbf{\Acl{til}:} The agent benefits from both intra-cluster and inter-cluster knowledge. The transfer of knowledge from other clusters is governed by the transferable knowledge fraction $\xi_{i,j} \in [0, 1)$, which is derived from the cluster similarity matrix $\bm{B}$. The term $\xi_{i,j}$ is defined as $\xi_{i,j} = \mathbb{I}_j^T (\bm{B} - I) \zeta_i$, where $\mathbb{I}_j$ is a one-hot vector for the skill's cluster and $\zeta_i$ is the vector of knowledge fractions from each cluster held by agent $i$. \textbf{\Acl{cl}:} This paradigm extends \ac{til} by adding inter-agent knowledge exchange. Agents share knowledge concurrently, governed by the inter-agent transfer gain matrix $\bm{\Gamma}$ (with entries $\gamma_{i,l} \in \mathbb{R}$). The dynamics for the remaining knowledge are
% % ---
% \begin{equation}
%  \dot{\bar{\sigma}}_{i,j}^{(CL)} = \left[ -\alpha_i\left(\frac{\eta_i\kappa + 1}{1 - \xi_{i,j}(\cdot)}\right) - \sum_{l \in \mathcal{N}(j)} \overline{\xi}_{i,l}(\cdot) \gamma_{i,l} d(\bar{\sigma}_{i,j}, \bar{\sigma}_{l,\cdot}) \right] \bar{\sigma}_{i,j}^{(CL)}   
% \end{equation}
% % ---
% \noindent This equation adds a new term for the knowledge received from other agents ($l \in \mathcal{N}(j)$), scaled by their respective transfer gains $\gamma_{i,l}$ and similarity fractions $\bar{\xi}_{i,l}$. The function $d(\cdot)$ models the integration of this shared knowledge. 


% A summary of the resulting learning rates and initial conditions for each paradigm is provided in Table 1.

% \subsection{Modeling Communication Energy ($E_{COMM}$)}

% The analyses in Results 2.1-2.4 focus on the energy saved in computation ($E_{CCE}$) and physical action ($E_{MIE}$). However, the CL paradigm itself introduces an energy cost not present in the other models: the Communication Energy ($E_{COMM}$) required for inter-agent knowledge exchange. To address the reviewer's feedback, we present a first-order model to estimate this overhead.

% We assume $E_{COMM}$ is the energy required to transmit a "skill package" (e.g., policy parameters, latent representations) from one agent to another.

% Let $S_k$ be the data size of one skill package. We assume a conservative size of $S_k \approx 10 \text{ MB}$.

% Let $P_{tx}$ be the power consumption of a standard Wi-Fi module during transmission, assumed to be $P_{tx} \approx 2.0 \text{ W}$.

% Let $R_{tx}$ be a realistic wireless data rate, $R_{tx} \approx 50 \text{ Mbps}$ (or $6.25 \text{ MB/s}$).

% The time to transmit one skill package is $T_{tx} = S_k / R_{tx} = 10 \text{ MB} / 6.25 \text{ MB/s} = 1.6 \text{ s}$.
% The energy cost for this single transfer is:

% $$e_{tx} = P_{tx} \times T_{tx} = 2.0 \text{ W} \times 1.6 \text{ s} = 3.2 \text{ J}$$

% This $E_{COMM}$ per-skill-transfer (3.2 J) is approximately five orders of magnitude smaller than the energy of a single physical learning episode ($e_0 \approx 105,600 \text{ J}$).

% Therefore, even if thousands of skills are shared across the collective during the full learning process, the total communication energy overhead is negligible compared to the CCE and MIE savings from avoiding millions of redundant learning episodes. This model confirms that the energy cost of communication does not negate the order-of-magnitude efficiency gains demonstrated in our case study.

% ####################################################################################################



% % ===================================================================================================
% %                                                 |                                                 |
% %                                                 |                                                 |
% % -------------------------------------------- SECTION ---------------------------------------------|
% %                                                 |                                                 |
% %                                                 |                                                 |
% % ===================================================================================================
% % \section*{Results}\label{sec:main_results}
% \section{Results}\label{sec:main_results}
% % % ---
% % \begin{figure*}[t!]
% % 	\centering
% % 	\hspace*{\fill}
% % 	\includegraphics[width=13cm]{collective_learning_and_skill_manifold_conceptualization.png}
% % 	\hspace*{\fill}
% %     \caption{\label{fig:collective_learning_and_skill_manifold_conceptualization} 
% %     	\textbf{Collective learning dynamics over an unknown structured skill manifold.} 
% %     	(\textbf{A}) \ac{eai} agents learn and share knowledge across a structured---however, inherently unknown---skill manifold. (\textbf{B}) The skill remaining knowledge dynamics $\dot{\bar{\sigma}}^{(\mathrm{CL})}_j$. (\textbf{C}) Three canonical \ac{cl} regimes: \textit{Destructive}---Fake news network---, learning inhibited by poor communication; \textit{Compensating}---network of fools---, weak agents supported by strong network; and \textit{Ideal}---network of knowledge---, synergistic learning across agents and network.   
% %     }
% % \end{figure*}
% % % ---

% % ===================================================================================================
% % \paragraph*{\Acl{cl} of a skill universe}
% \subsection{\Acl{cl} of a skill universe}
% For an \ac{eai} agent, \emph{data} is generated through interaction, which becomes \emph{information} when patterns and relationships---such as similarities between skills---are extracted during learning. Consequently, \emph{knowledge} is the structured and persistent competence that the agent distills from the acquired information. In this work, we do not aim to characterize knowledge in all its detail, nor to analyze specific individual learning capabilities of \ac{eai} agents or the properties of their network interactions. Instead, we address a fundamental question: \emph{how does inter-agent knowledge sharing shape the dynamics of learning?} by focusing on the general principles that govern collective knowledge integration.

% We consider a skill-learning scenario defined as the tuple
% % ---
% \begin{equation*}
% 	\phi = \left(N_\mathcal{S}, N_\mathcal{K}, N_\mathrm{r}, \bm{\rho} \right) \in \Phi,
% \end{equation*}
% % ---
% where $N_\mathcal{S}$ is the total number of skills to learn, $N_\mathcal{K}$ is the number of skill clusters, $N_\mathrm{r}$ is the number of \ac{eai} agents, i.e., the size of the collective, and $\Phi$ represents the set of all possible viable combinations. The parameter tuple
% % ---
% \begin{equation*}
% 	\bm{\rho} = \left(\bm{\alpha}, \bm{B}, \delta, \bm{\eta},\bm{\Gamma}\right),
% \end{equation*}
% % ---
% defines the knowledge exchange efficiency of the particular scenario; more details about these parameters are provided in \nameref{sec:methods} and depicted in Fig.~\ref{fig:collective_learning_and_skill_manifold_conceptualization}. Notice that the generality of $\Phi$ makes it representative of a variety of scenarios. It can very well be a smart factory setting where multiple robots learn different manufacturing tasks, a home crew of service robots learns different chores, or a fleet of underwater robots performs exploration, inspection, and maintenance routines.

% One example of a generic scenario $\phi$ is depicted in Fig.~\ref{fig:collective_learning_and_skill_manifold_conceptualization}, which illustrates a group of robots learning a universe of skills and the associated knowledge dynamics governing \ac{cl} in \ac{eai} systems distributed over a skill space with a similarity-based inherent structure. The notion of a \textit{skill manifold} $\mathcal{S}$ is shown in Fig.~\ref{fig:collective_learning_and_skill_manifold_conceptualization}~\textbf{A}, a structured latent space that represents the underlying similarity structure of a population of $N_\mathcal{S}$ skills. Individual skills group into $N_\mathcal{K}$ \emph{skill clusters} (green patches) based on their shared similarity metrics. For example, insertion tasks (left) and processing tasks (right) may form two distinct but internally (unobservable) coherent skill clusters.
% % ---
% \begin{definition}\label{def:robot_collective}
% 	A \emph{robot collective} is a group of $N_\mathrm{r}$ \ac{eai} agents that explore the skill manifold (without requiring prior knowledge of its structure). Each agent is equipped with an ad hoc \ac{ai} algorithm that leverages skill similarity to learn and store knowledge, as well as communication capabilities to exchange and integrate this knowledge with other peers.
% \end{definition}
% % ---
% \noindent Solid black lines connecting skills in Fig.~\ref{fig:collective_learning_and_skill_manifold_conceptualization}~\textbf{A} denote \textit{intra-cluster similarity}, promoting efficient incremental accumulation of knowledge from similar skills, while dashed lines linking clusters indicate \textit{intra-cluster similarity}, allowing more challenging but valuable cross-domain knowledge transfer, if performed successfully. Communication among agents and global knowledge storage allow concurrent skill knowledge accumulation, exchange, and integration within and across clusters.

% The expression shown in Fig.~\ref{fig:collective_learning_and_skill_manifold_conceptualization}~\textbf{B}---and detailed in Eq.~\eqref{eq:collective_knowledge_dynamics} in \nameref{sec:methods}---describes the dynamics of the to-be-learned knowledge $\dot{\bar{\sigma}}^{(\mathrm{CL})}_{i,j}$ about a skill~$j$ learned by an \ac{eai} agent~$i$ operating within a \ac{cl} system. This equation depends on four key parameters that govern system behavior. The \textbf{agent learning gain} $\alpha_i \sim \mathcal{U}(\alpha_{\text{min}},\alpha_{\text{max}}) \in \mathbb{R}_+$ captures the embodiment-dependent inherent ability of agent~$i$ to acquire knowledge about skill~$j$ in isolation; the learning gains across all agents are collected in the vector~$\bm{\alpha}$, with the range $[\alpha_{\text{min}}, \alpha_{\text{max}}]$ assumed to be narrow (according to Asm.~\ref{assumption:agent_similarity}). The \textbf{intra-cluster knowledge sharing gain} $\eta_i \sim \mathcal{N}(\bar{\eta},\eta_{\Sigma})$ quantifies how effectively agent~$i$ can reinforce a skill~$j$ through memory of related skills in the same cluster; the vector~$\bm{\eta}$ aggregates these gains across agents and models the efficient reuse of experience, such as accessing stored subskills $\zeta_k$ to support composite skills $s_{j,k}$. The structural similarity within the skill manifold is captured in the \textbf{inter-cluster similarity matrix} $\bm{B} \in \mathbb{R}^{N_\mathcal{K} \times N_\mathcal{K}}$; a corresponding vector~$\bm{\beta}_{ij}$ weighs the contribution of skills from other clusters in the agent’s local memory to the learning of a new skill~$j$. Finally, the \textbf{inter-agent transfer gains} $\gamma_{j,l} \sim \mathcal{N}(\bar{\gamma},\gamma_\Sigma)$, collected in the matrix~$\bm{\Gamma} \in \mathbb{R}^{N_\mathrm{r} \times N_\mathrm{r}}$, model the flow of knowledge between agents, accounting for embodiment differences, communication noise, and variation in prior experience. In addition to these four interaction terms, the model includes the intrinsic intelligence $\delta \in (0,\delta_{\text{max}}]$ of the system, controlling also the \textbf{exponential depletion rate} of initially available knowledge.

% In addition, the \textbf{number of learned skills}~$\kappa_{i,k}$ from each cluster~$k$ retained in agent~$i$’s memory also influences the dynamics, affecting the knowledge acquisition rate of a skill and the corresponding initial knowledge. Collectively, the parameters $\bm{\rho}$ determine whether the residual knowledge about a skill decreases---indicating successful learning---or increases, which may signal knowledge corruption or forgetting, depending on both individual and collective learning processes.

% % ===================================================================================================
% % \paragraph*{Knowledge dynamics from different learning paradigms}
% \subsection{Knowledge dynamics from different learning paradigms}
% We distinguish learning paradigms in \ac{eai} according to how knowledge is acquired and reused across skills. In \ac{isl}, each skill is learned independently from scratch, without leveraging prior experience. By contrast, \ac{il} denotes the reuse of knowledge from similar, previously mastered intra-cluster skills, thereby improving efficiency through structural similarity. \Ac{tl} extends this principle to inter-cluster reuse, where knowledge from one or more origin clusters accelerates learning in a destination cluster. This process is governed by the \emph{transferable knowledge fractions} $\xi_k$ and $\bar{\xi}_k$, which are determined by the cluster similarity matrix $\bm{B}$. The combined paradigm, \ac{til}, exploits both intra- and inter-cluster generalization. Details on the mathematical formalization of these paradigms are provided in \nameref{sec:methods} and further illustrated in the \nameref{sec:supplementary_materials} (Sec.~\ref{sec:conventional_learning_paradigms}).

% In conventional paradigms, parallelization enables multiple agents to learn simultaneously; however, integrating their knowledge remains impossible without communication. By contrast, \acl{cl} goes beyond parallel learning: a collective of $N_\mathrm{r}$ robots builds a shared knowledge base through real-time communication, combining vertical transfer of prior knowledge with horizontal sharing of ongoing experiences. Under a \ac{cl} scheme, the \ac{eai} agents operate in a regime of \ac{slad}, where skill knowledge is integrated collectively through ongoing interaction. We further elaborate on our structural reinterpretation of incremental and transfer learning—contrasting it with the procedural conventions of machine learning—in the \nameref{sec:discussion}, where we also situate the recent advances of foundation models within our knowledge dynamics framework.

% % % ---
% % \begin{table}[!t]
% %     \caption{The dynamics of the remaining knowledge for the considered learning paradigms.\label{tab:learning_paradigms_expressions}}
% %     \begin{center}
% %         \begin{adjustbox}{width=\textwidth}
% %             \begin{tabular}{
% %                 >{\raggedright\arraybackslash}p{3cm} 
% %                 *{3}{>{\centering\arraybackslash}p{3cm}}
% %                 *{1}{>{\centering\arraybackslash}p{6.5cm}}
% %             }            
% %                 \toprule
% %                 \textbf{Learning Paradigm} 
% %                 & \textbf{\ac{isl}} 
% %                 & \textbf{\ac{il}} 
% %                 & \textbf{\ac{til}} 
% %                 & \textbf{\ac{cl}} \\
% %                 \midrule
% %                 Learning rate 
% %                 & $-\alpha_i$ 
% %                 & $-\alpha_i\:\left(\eta_i \kappa + 1 \right)$ 
% %                 & $-\alpha_i\:\left( \frac{\eta_i \kappa + 1}{1 - \xi_{i,j}(\cdot)} \right)$ 
% %                 & $-\alpha_i\:\left( \frac{\eta_i \kappa + 1}{1 - \xi_{i,j}(\cdot)} \right) - \sum_{l \in \mathcal{N}(j)}\bar{\xi}_{i,l}(\cdot)\gamma_{i,l}d(\cdot)$ \\
% %                 \addlinespace[0.5ex]
% %                 Initial condition 
% %                 & $1$ 
% %                 & $e^{-\delta \kappa}$ 
% %                 & $\left(1-\xi_{i,j}(\cdot)\right)\: e^{-\delta \kappa}$ 
% %                 & $\left(1-\xi_{i,j}(\cdot)\right)\: e^{-\delta \kappa}$ \\
% %                 \bottomrule
% %             \end{tabular}
% %         \end{adjustbox}
% %     \end{center}
% % \end{table}
% % % ---

% To rigorously compare the knowledge acquisition capabilities across learning paradigms, we derived Eq.~\eqref{eq:collective_knowledge_dynamics} as a unifying model that captures the dynamics of the remaining knowledge to be acquired in each case. This formulation makes explicit the structural differences among isolated, incremental, transfer, and \acl{cl}, while revealing how collective knowledge integration gives rise to emergent compositionality---the process through which shared fragments of skill knowledge integrate to achieve novel competencies.

% The resulting closed-form expressions for all paradigms, summarized in Table~\ref{tab:learning_paradigms_expressions}, provide a direct analytical basis to quantify and contrast their efficiency.

% % % ---
% % \begin{figure*}[t!]
% % 	\centering
% % 	\hspace*{\fill}
% % 	\includegraphics[width=14cm]{collective_learning_cases.png}
% % 	\hspace*{\fill}
% % 	\caption[] {\label{fig:collective_learning_cases} \textbf{Canonical regimes of a \acl{cl} system.} Robot collectives exhibit distinct behaviors depending on the mean values of $\eta$ and $\gamma$, affecting the total learning episodes (and thus energy) and success rate. Four principal regimes are identified: (\textbf{A}) destructive, (\textbf{B}) canceling, (\textbf{C}) ideal, and (\textbf{D}) compensating. (\textbf{E}) Collective size influences both learning efficiency and success.}
% % \end{figure*}
% % % ---

% % % ---
% % \begin{figure*}[t!]
% % 	\centering
% % 	\hspace*{\fill}
% % 	\includegraphics[width=14cm]{cases_point_plot.png}
% % 	\hspace*{\fill}
% % 	\caption[] {\label{fig:cases_point_plot} \textbf{Collective size influences both learning efficiency and success.} The size of the robot collective can steer the learning of the skill universe, leveraging the positive influence of $\bar{\gamma}$.}
% % \end{figure*}
% % % ---

% % ===================================================================================================
% % \paragraph*{Canonical \acl{cl} regimes}
% \subsection{Canonical \acl{cl} regimes}
% The \acl{cl} behavior of a system depends crucially on two key parameters: the mean intra-agent knowledge retention $\bar{\eta}$ and the mean inter-agent knowledge transfer gain $\bar{\gamma}$. Recall that the parameter $\bar{\eta}$ captures the average quality of learning from prior knowledge at the individual level. Thus, a high $\bar{\eta}$ implies robust and consistent knowledge accumulation within each robot, whereas a low $\bar{\eta}$ signals erratic internal learning or even degradation of stored knowledge. Conversely, $\bar{\gamma}$ characterizes the integrity and effectiveness of knowledge exchange across the agent network. A high $\bar{\gamma}$ enables constructive, reliable sharing of skills, while a low value reflects corruption due to issues like noisy communication, concept drift, or divergent objectives.

% To analyze how these two factors shape system-level dynamics, we studied an idealized scenario---the particulars of this scenario are provided in the \nameref{sec:supplementary_materials} Sec.~\ref{sec:cl_scenarios_supplementaries}---where each of the $N_\mathrm{r}$ \ac{eai} agents in the collective learns a different skill in every learning cycle---i.e., all the episodes required to learn a given skill batch. Based on all possible combinations of $\bar{\eta}$ and $\bar{\gamma}$, we identified nine canonical \ac{cl} regimes that can be categorized further into four principal regimes. Fig.~\ref{fig:collective_learning_and_skill_manifold_conceptualization}~\textbf{C} illustrates three of these principal regimes, each depicted through a schematic of agent-skill-manifold interaction, Gaussian distributions over $\eta$ and $\gamma$, and performance plots indicating the number of learning episodes required to acquire all $N_\mathcal{S}$ skills as a function of collective size. It is worth mentioning that, since, for simplicity, the energetic cost $ e_0 $ of a learning episode is assumed to be constant, the total energy expenditure to learn all skills is directly proportional to the total number of learning episodes.

% In the \textbf{destructive regime}---referred to as the \emph{``Fake News Network''}---competent agents ($\bar{\eta} > 0$) are misled by faulty collective interactions ($\bar{\gamma} < 0$). Despite having robust internal learning, agents suffer from corrupt external knowledge that spreads rapidly, resulting in reduced system performance. In contrast, the \textbf{compensating regime}, labeled \emph{``Network of Fools''}, features agents with poor internal learning ($\bar{\eta} < 0$) supported by a strong and reliable collective ($\bar{\gamma} > 0$). This collective structure compensates for individual shortcomings, reducing the number of learning episodes with increasing collective size. The \textbf{ideal regime}, or \emph{``Network of Knowledge''}, emerges when both agent-level and network-level learning are stable and constructive ($\bar{\eta} > 0, \bar{\gamma} > 0$). Here, the system achieves maximal efficiency and minimal energy expenditure in distributed skill acquisition.

% Beyond these principal regimes, analysis of the individual canonical regimes provides further insight. As visualized in the performance plots of Fig.~\ref{fig:collective_learning_cases}, in \textbf{Case 1}, agents retain knowledge well, but collective communication is destructive. This leads to rapid decay in success rates due to corrupted knowledge propagation. \textbf{Case 2} is similar: agents learn effectively, but the network only partially degrades knowledge—failures may result from misaligned updates, stale messages, or adversarial sharing. \textbf{Case 3} represents the ideal, where both individual and collective learning reinforce each other, yielding scalable and efficient performance. 

% In \textbf{Case 4}, both the agents and the collective behave erratically, compounding instability. \textbf{Case 5} shows partial recovery from this: some learning occurs due to stochastic factors or sparse data, which might be stabilized via architectural or procedural improvements. \textbf{Case 6} features agents that intermittently reuse prior knowledge, supported by a cooperative collective—resulting in success, albeit at a higher complexity cost than in Case 3.

% \textbf{Case 7} presents the worst scenario, with both agents and the network actively destroying knowledge, possibly due to catastrophic forgetting, model collapse, or uncoordinated learning. In \textbf{Case 8}, agents corrupt knowledge individually, but the network offers some structure; with sufficient scale, even this erratic setting can yield learning. Finally, \textbf{Case 9} demonstrates that even when individual agents degrade knowledge, a robust collective can ensure successful learning through strong knowledge sharing.

% As already mentioned, we clustered the nine canonical regimes into four principal regimes, as shown in Fig.~\ref{fig:collective_learning_cases}: \textbf{(A)} destructive regimes (Cases 1, 4, 7), \textbf{(B)} canceling regimes (Cases 2, 5), \textbf{(C)} ideal regimes (Cases 3, 6), and \textbf{(D)} compensating regimes (Cases 8, 9). The \textbf{canceling regime} strikes a delicate balance: while all skills can still be learned, the required number of episodes is significantly higher than in the ideal case, implying a higher energy cost. Overall, the performance plots in Fig.~\ref{fig:collective_learning_cases} emphasize that system-wide success in \acl{cl} depends more on robust inter-agent connectivity and shared knowledge dynamics than on isolated learning capabilities. This is particularly evident in compensating cases (8 and 9), where large collectives overcome individual agent weaknesses through stable, redundant communication structures. In particular, the most efficient regimes exhibit \emph{compositional growth of knowledge}, where collective experiences integrate synergistically to accelerate the acquisition and synthesis of skills across the \ac{eai} agents. To also highlight the influence that the size of the collective has in the different regimes, Fig.~\ref{fig:cases_point_plot} shows the total learning episodes and the success rate, defined as the percentage of skills successfully learned, for all regimes. Depending of parameters ($\bar{\eta},\bar{\gamma}$) the size of the collective can bring the system from a successful learning state to an entire obliteration of the knowledge capability (as in Case 1), while in Cases 8 and 9, the growing size of the collective drives the system towards successful learning of the skill universe, in spite of the individual learning limitations.


% % ===================================================================================================
% % \paragraph*{A smart factory case study}
% \subsection{A smart factory case study}
% % % ---
% % \begin{figure*}[t!]
% % 	\centering
% % 	\hspace*{\fill}
% % 	\includegraphics[width=16cm]{smart_factory_case_study.png}
% % 	\hspace*{\fill}
% % 	\caption[] {\label{fig:smart_factory_case_study} \textbf{Smart sensor manufacturing.} {(\textbf{A}) A factory manufactures a new smart sensor every shift. During downtime, a robot collective might need to learn a new set of skills to manufacture the new sensor. (\textbf{B}) The skills seen by the collective, according to the number of products, (\textbf{C}), the learning episodes required to learn a product, and (\textbf{D}), the total learning energy required to master all skills. %\TODO{Run more times to smooth the plot.}
% %     }}
% % \end{figure*}
% % % ---

% In this second scenario, we run a case study of a smart factory setting where multiple robots learn different numbers of skills required for the manufacturing of a given product; in our case, advanced smart sensors. This use case emphasizes sample-efficient, real-world learning of manipulation skills to support flexible reconfiguration of work cells to manufacture different types of smart sensors. To resemble the conditions implied in Assumptions~\ref{assumption:average_behavior}, \ref{assumption:agent_similarity},~\ref{assumption:cluster_size}, and~\ref{assumption:cluster_transferability}, a prototypical skill learning scenario $\phi_\text{SF}$ for the smart  factory involves several robots performing multiple skills in different clusters. In this particular case, we settle for a smaller collective of $N_\mathrm{r} = 8$ robots and keep the values for the remaining elements of $ \bm{\rho} $ as in the previous scenario. 

% The smart factory consists of flexible, reconfigurable work cells tailored to specific manufacturing processes (that is, component placement, soldering, assembly, testing, and packaging), enabling rapid adaptation to new tasks and components. Within these cells, robots perform different skills, such as \textit{pick-and-place}, \textit{gripping and handling}, \textit{component orientation}, \textit{precise solder application}, \textit{optical inspection}, \textit{force testing}, \textit{printed-circuit-board handling}, and the like \cite{Kirschner2025CategorizingRB}. 

% When a new sensor is required, that is, in changeover time, a new set of skills is required to manufacture the sensor. Under the assumption that hardware stays constant, this implies a production downtime period where the \ac{eai} agents need to learn these skills, see Fig.~\ref{fig:smart_factory_case_study}~\textbf{A}. For example, in one shift, the product $ P_\mathrm{A} $ is manufactured and requires robots to learn skills from three skill clusters ($ P_\text{A}\subset\mathcal{Z}_1 \cup\mathcal{Z}_2\cup\mathcal{Z}_4 $). At changeover time, now the skills needed to manufacture a new product $ P_\mathrm{B} $ are required ($P_\text{B}\subset\mathcal{Z}_1\cup\mathcal{Z}_3\cup\mathcal{Z}_4 $). For simplicity, we assume that every new product requires $ p $ skills and there may be repeated (already seen) skills in the skills of different products. Furthermore, we let $ N_\mathrm{r} \geq p $. The question in this scenario is to see whether \ac{cl} reduces the changeover downtime $ T_\mathrm{CO} $ to a minimum. In other words, it is desired to reduce the number of episodes required to learn the skills for a new sensor type to be manufactured. Using the conditions posed by the skill learning scenario $ \phi_\text{SF}$, we show that the effect of the inherent compositionality on the speed of knowledge acquisition is significantly amplified through \ac{cl}. This lowers both the downtime and energy required to acquire the necessary skills across all products.

% The power-per-episode (see Asm.~\ref{assumption:power_and_episode_time}) is determined by the sum of the power required for basal processes, the power for motion and interaction, and the power for computation and communication, i.e.,
% % ---
% \begin{equation}
% 	P_0 = P_\text{bbe} + P_\text{MIE} + P_\text{CCE}.
% \end{equation}
% % ---
% To assign a numerical value to $P_\text{bbe}$, and without loss of generality, we consider $\phi_\text{SF}$ an instance of a smart factory populated with state-of-the-art tactile robots~\cite{Kirschner2025CategorizingRB}, like those listed in Sec.~\ref{sec:app_cobot_ener_consumption} of the \nameref{sec:supplementary_materials}, which require a typical operational power of about $\unit[40]{W}$ (plus the compute power for basic functionalities). To approximate $P_\text{MIE}$, we estimate that in demanding tasks, the power requirement of a cobot and a tactile robot can be upper-bounded around $ \unit[300] {W} $. Finally, to determine $P_\text{CCE}$, we assume that, to deal with the computing effort that learning new skills will have on the robots' local processors, the smart factory will delegate the computational burden to a remote computing unit, i.e., cloud computing. Thus, we take as reference the work in \cite{Strubell2019EnergyPolicyConsiderations}, where a state-of-the-art machine learning algorithm executed in a cluster required $\unit[1.42]{kW}$ to solve a task. Finally, we can assume that the execution of each trial episode $n$ takes $\Delta t = 60$ seconds. Using these reference values, we can estimate that, when learning a skill, an average trial episode has an energetic demand of
% % ---
% %\begin{equation}
% %	e_0 = P_0 \Delta t = \left(40 + 300 + 1,415.78\right) \left(60\right) \approx 105~\text{kJ}.
% %\end{equation}
% \begin{equation}
% 	e_0 = P_0 \Delta t \approx 105~\text{kJ}.
% \end{equation}
% % ---

% Figure~\ref{fig:smart_factory_case_study}~\textbf{B} shows the learning progress in terms of the number of skills that have been seen as the number of products increases. Correspondingly, the number of episodes required to learn the batches of skills corresponding to different products is depicted in Fig.~\ref{fig:smart_factory_case_study}~\textbf{C}. It can be observed that, close to the 20 product mark, all other skills can be learned practically instantaneously (zero-shot learning). This means that the downtime associated with learning the skills for a product is negligible at this point. For comparison, similar plots for the conventional paradigms of \ac{isl}, \ac{il}, and \ac{til} are also provided (see \nameref{sec:methods} for more details). In these paradigms, there is no inter-agent knowledge exchange, which clearly impacts the number of learning episodes required. As expected, \ac{isl} exhibits the worst performance, always requiring $c_0$ episodes to learn every skill. \ac{il} shows improvement, but does not benefit from knowledge in other skill clusters. This is not the case in \ac{til}, as a robot can exploit the knowledge of the clusters it has visited. Finally, the speed of knowledge collection is exponentiated with \ac{cl}---reflected in the number of learning episodes---thanks to the exchange of knowledge among the $N_\mathrm{r}$ robots in the collective. Compared to the other learning paradigms, with \ac{cl}, a batch of skills (that is, a new product) is learned in a few episodes. This last fact is directly related to the energy required by the collective to learn all $N_\mathcal{S}$ skills. The bar plot in Fig.~\ref{fig:smart_factory_case_study}~\textbf{D} shows the energy required for each paradigm for all the learning episodes. \Acl{cl} uses only about 10~\% of the energy required by its closest competitor, \acl{til}.

% % ===================================================================================================
% %                                                 |                                                 |
% %                                                 |                                                 |
% % -------------------------------------------- SECTION ---------------------------------------------|
% %                                                 |                                                 |
% %                                                 |                                                 |
% % ===================================================================================================
% % \section*{Discussion}\label{sec:discussion}
% \section{Discussion}\label{sec:discussion}

% This work establishes a principled foundation for understanding and optimizing energy efficiency in \acl{eai} systems through the lens of \acl{cl}. We began by identifying three grand energy challenges posed by \ac{dai} and the growing population of robots: the escalating computational load, the increasing energy footprint of physical agents, and the manufacturing-related energy costs. We then introduced a formal framework for modeling energy expenditure in \ac{eai} agents and demonstrated that traditional learning paradigms---isolated, incremental, and transfer learning---fail to scale efficiently with system and skill universe size. In contrast, \acl{cl}, characterized by structured intra- and inter-agent knowledge exchange, emerged as a paradigm capable of accelerating learning and significantly reducing energy demands. Through analytical modeling and simulation studies, we revealed nine canonical \ac{cl} regimes and identified four principal behaviors---destructive, canceling, ideal, and compensating---that capture the interplay between individual and collective learning dynamics. Our results show that \ac{cl} can reduce energy consumption by at least an order of magnitude compared to the paradigms that neglect inter-agent knowledge sharing, especially in realistic smart factory settings. These results identify \ac{cl} as a scalable and energy-efficient framework for sustainable embodied \ac{ai}, in which efficiency derives from \emph{collective knowledge composition}: distributed agents cooperatively integrate prior knowledge to synthesize new capabilities with exponential improvements in learning efficiency.

% % % ---
% % \begin{figure*}[t!]
% % 	\centering
% % 	\hspace*{\fill}
% % 	\includegraphics[width=16cm]{learning_paradigms_and_size_of_collective.png}
% % 	\hspace*{\fill}
% % 	\caption[] {\label{fig:learning_paradigms_and_size_of_collective} \textbf{Effect of the collective size on the total number of learning episodes.} {(\textbf{A}) In the classical paradigms, even when learning in parallel, each agent holds its own memory and can only access the subset of knowledge corresponding to the skills it has seen. This effectively splits the total knowledge. The more agents, the less available knowledge per agent. (\textbf{B}) The plot shows that as a result of having more agents, the classical paradigms degrade the learning and converge to \acl{isl}. On the contrary, \acl{cl} exploits the number of robots, exponentiating the learning as a result.}}
% % \end{figure*}
% % % ---

% % ===================================================================================================
% % \paragraph*{Splitting knowledge vs. sharing knowledge}
% \subsection{Splitting knowledge vs. sharing knowledge}
% The performance plots in Fig.~\ref{fig:collective_learning_cases} showed different \ac{cl} regimes for a varying size of the collective. It is also important to look at how the other discussed learning paradimgs behave based on the number $N_\mathrm{r}$ of \ac{eai} agents in the collective, which is directly related to the the total number of trial episodes $C_\mathcal{S}$ required to learn all the $N_\mathcal{S}$ skills, and, hence, to the learning energy expenditure via the constant $e_0$. The results of this analysis are shown in Fig.~\ref{fig:learning_paradigms_and_size_of_collective}. The first immediate implication of the lack of knowledge sharing among agents is that the total knowledge is effectively partitioned among the agents in the collective. This is conceptually illustrated in Fig.~\ref{fig:learning_paradigms_and_size_of_collective}~\textbf{A}, where four robots---identified in different colors for clarity---travel the skill manifold learning an equal number of skills in parallel. As the learning cycles progress, each agent holds in its memory a share of the total knowledge (depicted by the colored areas). It follows, that the more agents are in the collective, the more the total knowledge is partitioned among all the agents. This effect is shown in Fig.~\ref{fig:learning_paradigms_and_size_of_collective}~\textbf{B}, where it can be seen that, initially, \ac{il} is better than the trivial \ac{isl} case; however, as the collective size increases, the skill knowledge is divided among the available robots, which implies that less knowledge can be passed as the pool of learned skills $\zeta_k$ per robot decreases. This explains why the total number of trial episodes for \ac{isl} and \ac{il} approach each other in the limit. With a growing collective size, \ac{til} exhibits a similar behavior. Less cluster knowledge can be collected by each robot and transferred to a target cluster. With a larger collective, \ac{til} rapidly converges to \ac{il} and eventually to \ac{isl}. Unlike these conventional paradigms, in \ac{cl}, as the size of the collective robots grows, the total complexity keeps decreasing as a result of the knowledge exchange from all the robots learning skills from different clusters at the same time.

% % ===================================================================================================
% % \paragraph*{On the regimes of \acl{cl} systems}
% \subsection{On the regimes of \acl{cl} systems}
% The dynamics of a \ac{cl} system are shaped by multiple interacting factors, including differences in embodiment, inaccuracies in communication, breaches in synchronization, updates to learning parameters, and the correctness of the information exchanged. These factors manifest through variations in the key model parameters: the agents learning rates $\bm{\alpha}$, the intra-agent retention gains $\bm{\eta}$, and the inter-agent exchange gains in the matrix $\bm{\Gamma}$. As discussed in \nameref{sec:methods}, Assumptions~\ref{assumption:average_behavior} and~\ref{assumption:agent_similarity} constrain embodiment heterogeneity, which primarily influences $\alpha$, the rate at which an agent acquires new skills in isolation. While the individual entries in $\bm{\alpha}$ affect the speed of learning, it does not qualitatively change whether learning succeeds or fails. In contrast, $\bm{\eta}$ reflects an agent’s ability to reuse and reinforce previously acquired knowledge. Since it is sensitive to the similarity structure of skills within a cluster, low vaues in $\bm{\eta}$ can actively hinder the learning process, even in otherwise competent agents. Nevertheless, the system-level behavior remains robust if the average values of the entries in the inter-agent transfer matrix $\bm{\Gamma}$ are chosen appropriately to maintain the stability of knowledge sharing across the collective. One of the most compelling findings is the existence of regimes in which \ac{cl} outperforms conventional, isolated learning paradigms. These regimes---particularly the ideal and compensating ones---emerge within realistic parameter ranges and demonstrate how even weak or noisy agents can succeed collectively through effective knowledge exchange and integration. This highlights the practical relevance and potential of \ac{cl} systems as scalable, fault-tolerant architectures for distributed intelligence.

% % % ---
% % \begin{figure}[!th]
% % 	\centering
% % 	\includegraphics[width=0.45\textwidth]{fig/grand_challenges_connections.png}
% % 	\caption{\textbf{Interconnection between energy challenges C1, C2, and C3.}}
% % 	\label{fig:challengesConnected}
% % \end{figure}
% % % ---


% % ===================================================================================================
% % \paragraph*{Developing collective learning to address the energy challenges of \acl{eai}}
% \subsection{Developing collective learning to address the energy challenges of \acl{eai}}

% \Acl{cl} directly speaks to each of the three grand energy challenges introduced earlier. The natural connections between these challenges---shown in Fig.~\ref{fig:challengesConnected}---and their association with \ac{eai} allow us to identify critical areas of opportunity for \ac{cl}.
% \newline
% (C1) Computation and communication energy ($E_\text{CCE}$).
% In current practice, every robot or \ac{ai} system repeatedly computes policies or retrains models in isolation. This multiplies the demand for GPU clusters and cloud resources. By contrast, \ac{cl} allows skills acquired by one agent to be stored, exchanged, and reused by others. Instead of thousands of redundant training runs across agents, the collective can converge after a few representative experiences, with subsequent agents retrieving stored knowledge. Over time, this shifts the resource profile from expensive parallel training toward lighter operations such as querying and incremental updates, which drastically reduces GPU hours and associated data center energy.
% \newline
% (C2) Energy footprint of physical robots ($E_\text{bbe}$ and $E_\text{MIE}$).
% Physical learning is costly: each trial requires actuation, sensing, and interaction with the environment. In conventional paradigms, multiple robots would each practice the same task, consuming energy in proportion to the collective size. In principle, with \ac{cl}, only a subset of robots needs to explore a skill physically; others can learn from their experience through structured knowledge transfer. This shortens the number of required trials per agent, lowers total motion and interaction energy, and reduces downtime in settings like smart factories where production stops during learning phases. In other words, \ac{cl} minimizes how often robots must ``burn electricity to move'' in order to master skills.
% \newline
% (C3) Manufacturing-related energy.
% The energy demand associated with producing more and more robotic and computational hardware grows with the size of the collective. \ac{cl} indirectly addresses this challenge by enabling better use of existing robots. If robots learn faster and more efficiently through knowledge sharing, fewer redundant units are required to maintain productivity, and existing fleets can adapt to new tasks without costly hardware replacement. Furthermore, by reducing retraining loads and unnecessary trial-and-error wear, \ac{cl} can extend the service life of robots and electronic components, thereby lowering the frequency of new production cycles and amplifying the benefits of recycling strategies.
% \newline
% Taken together, these links show that \ac{cl} is not just a conceptual advance but a practical lever for reducing energy demand across all layers of embodied \ac{ai}---from cloud computation, to real-world robot trials, to manufacturing pipelines.

% % ===================================================================================================
% % \paragraph*{Reinterpreting Incremental and Transfer Learning in the Age of Foundation Models}
% \subsection{Reinterpreting Incremental and Transfer Learning in the Age of Foundation Models}
% To situate our framework within the broader landscape of machine learning, we revisit the notions of incremental and transfer learning in light of recent advances in large-scale foundation models. Our interpretation of \ac{il} and \ac{tl} differs from the conventional acceptations in the machine learning community. \Ac{il} is typically defined as the sequential update of model parameters to prevent forgetting, while \ac{tl} refers to reusing pre-trained knowledge across domains through fine-tuning. In our framework, however, these notions are defined structurally: \ac{il} corresponds to \emph{intra-cluster reuse}, where knowledge acquisition rates scale with the number of learned skills, and \ac{tl} corresponds to \emph{inter-cluster reuse}, governed by transferable fractions and the similarity matrix~$\bm{B}$. A comparative summary of these distinctions is provided in Table~\ref{tab:IL_TL}.

% By contrast, recent advances in large language, vision--language(-action), and other foundation models are often framed as exhibiting \ac{il} or \ac{tl}, since pre-trained generalist policies can later be fine-tuned for specific tasks. Yet their underlying mechanisms differ fundamentally from the idealized learning paradigms as considered in our work. Foundation models are trained on vast data sets---such as natural language, multimodal, or cross-embodiment corpora---and adapted via prompting, fine-tuning, or retrieval-augmented generation (RAG). This process does not constitute genuine \ac{il} within a domain, nor structured \ac{tl} across domains. Instead, it reflects large-scale statistical pattern matching: correlations extracted in one representational universe are repurposed in another, without explicit exploitation of transferable skill knowledge. Within the context of skill learning, the information encoded in a foundation model may offer only a coarse approximation of a skill, obtained without embodied interaction and therefore bypassing the \ac{slad} challenge.

% The idealized knowledge dynamics described by Eq.~\eqref{eq:collective_knowledge_dynamics} capture the composition of new skill knowledge through the continuous integration of knowledge bits from all \ac{eai} agents. In contrast, foundation models undergo a one-time global training (learning) phase followed by static inference. Their inference stage bears a superficial resemblance to \ac{tl}, as pre-trained knowledge is reused across tasks; yet inference can be seen as effectively providing only an initial condition for the knowledge integrator. Even when combined with RAG, such systems remain incapable of genuine \ac{il}, as they cannot incorporate new knowledge dynamically through interaction. Recent efforts to fuse foundation models with reinforcement learning~\cite{firoozi2025foundation} attempt to complement this limitation with reinforcement learning viewed as a specific form of \ac{il}, where experience incrementally refines a policy under a reward function.

% While explicit skill similarity is not exploited in foundation models, limited forms of transfer may occur between ``skill universes'' that share comparable similarity structures, where only the domain-specific data layer changes. In such cases, skills that appear transferable across representational universes do not arise from genuine knowledge integration or discovery. Beyond this epistemic limitation lies an energetic one: foundation models externalize learning into massive, centralized pretraining cycles, whereas \ac{cl} distributes it across many embodied agents that generate, exchange, and refine knowledge in real time. This transition from statistical accumulation to distributed embodiment points toward a more scalable and energetically sustainable paradigm for \ac{eai}.

% % ===================================================================================================
% % \paragraph*{Closing remarks}
% \subsection{Closing remarks}
% Although unprecedented strides in \ac{ai} and robotics have revolutionized numerous sectors, the ongoing proliferation and associated energy escalation cannot be ignored. As the scope of \ac{ai} continues to expand, a concerted effort is required to strike a balance between innovation and conscientious use of energy to steer \ac{ai} toward sustainable operation.

% To emphasize the importance of energy demands in \ac{ai} systems, we discussed three principal categories of energy expenditure and contrasted them with the great challenges posed by the increase in \acl{dai} applications and the growing population of \ac{eai} agents. In particular, we underscored that mitigating energy consumption in \ac{eai} systems requires not only improved mechanical designs and efficient computational and communication hardware, but also a paradigm shift toward sharing, exchange, transfer, and accumulation of knowledge acquired by individual agents.

% As discussed in \cite{Kaelbling2020foundationefficientrobot}, efficient robotic learning algorithms must exhibit several key attributes to enable agents to acquire new skills on the fly: sample efficiency, generalizability, compositionality, and incremental learning capabilities. The \acl{cl} paradigm inherently fulfills these requirements by leveraging the full communication potential of networked \ac{eai} agents. This approach supports real-time, concurrent knowledge exchange and integration, yielding both energy- and time-efficient skill acquisition.

% Our results show that relying on conventional paradigms--such as isolated, incremental, or transfer learning, as is also the case for foundation models---for large numbers of \ac{eai} agents leads to suboptimal energy utilization. Even when agents operate concurrently, the absence of genuine inter-agent knowledge exchange causes energy demands to scale inefficiently with agent population size. In contrast, our simulation study shows that \ac{cl} provides a compelling solution, especially when skill similarity guides the exchange process. In particular, the \ac{cl} paradigm achieved vastly improved performance as the number of robots increased, enabling concurrent learning of multiple skills with improved energy efficiency.

% Although the promise of \ac{cl} is clear, it is important to acknowledge that the foundational algorithms and infrastructure required to realize this paradigm are either still in development or yet to be established. Even state-of-the-art approaches to incremental and transfer learning (e.g., reinforcement learning, vision-language-action models, and foundation models) remain in the early stages. However, although our main focus has been on the energy efficiency of the \ac{eai} systems, the implications of \ac{cl} extend well beyond this domain.

% The \ac{cl} paradigm is equally relevant to \ac{dai} agents. Recent advances in edge computing and federated learning illustrate this potential, as they shift computational tasks from centralized data centers to the periphery, where \ac{dai} agents operate. Additionally, foundation models--trained through extensive learning efforts---are increasingly being reused and fine-tuned to solve more specific, nuanced tasks, demonstrating the value of effective knowledge transfer.

% As in \ac{eai}, the advantages of \ac{cl} for \ac{dai} become evident when efficient mechanisms for knowledge exchange and integration are established among agents who execute their own learning routines. The synergies enabled by this paradigm can significantly increase both problem-solving capacity and energy efficiency in a wide range of \ac{dai} applications.

% In conclusion, the \acl{cl} approach holds the potential to address key challenges at the intersection of energy efficiency, scalability, and adaptability in both embodied and distributed \ac{ai}. Our arguments and results can catalyze further research and development efforts, ultimately advancing the realization of collective learning across the entire spectrum of the \ac{ai} domains.


% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
% \section*{Supplementary Materials}
\section{Supplementary Materials}
Sections \ref{sec:ai_grand_challenges} to \ref{sec:related_works}\\
Figures~\ref{fig:eai_and_dai_concept_figure} to \ref{fig:cobot_watt_per_kg}

% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
\renewcommand\refname{References and Notes}
\bibliography{bib/References.bib}
\bibliographystyle{Science}

%\begin{thebibliography}{10}
%	
%	\bibitem{Szczepanski2019Economicimpactsartificial}
%	M.~Szczepanski, Economic impacts of artificial intelligence ({AI}) (2019).
%	
%	\bibitem{Strubell2019EnergyPolicyConsiderations}
%	E.~Strubell, A.~Ganesh, A.~McCallum, {\it Energy and Policy Considerations for
%		Deep Learning in NLP\/}, {\it ACL\/} (2019).
%	
%	\bibitem{Cao2020TowardsAccurateReliable}
%	Q.~Cao, A.~Balasubramanian, N.~Balasubramanian, {\it Towards Accurate and
%		Reliable Energy Measurement of {NLP} Models\/}, {\it Proceedings of
%		SustaiNLP: Workshop on Simple and Efficient Natural Language Processing\/}
%	(Association for Computational Linguistics, Online, 2020), pp. 141--148.
%	
%	\bibitem{Chebotar2019Closingsimreal}
%	Y.~Chebotar, {\it et~al.\/}, {\it Closing the sim-to-real loop: Adapting
%		simulation randomization with real world experience\/}, {\it 2019
%		International Conference on Robotics and Automation (ICRA)\/} (IEEE, 2019),
%	pp. 8973--8979.
%	
%	\bibitem{Lehdonvirta2022futuresunpaidwork}
%	V.~Lehdonvirta, L.~P. Shi, E.~Hertog, N.~Nagase, Y.~Ohta, {\it The future (s)
%		of unpaid work: How susceptible do experts from different backgrounds think
%		the domestic sphere is to automation?\/}, {\it Plos one\/} {\bf 18}, e0281282
%	(2023).
%	
%	\bibitem{andrae2015global}
%	A.~S. Andrae, T.~Edler, {\it On global electricity usage of communication
%		technology: trends to 2030\/}, {\it Challenges\/} {\bf 6}, 117 (2015).
%	
%	\bibitem{Hintemann2022Cloudcomputingdrives}
%	R.~Hintemann, S.~Hinterholzer, Cloud computing drives the growth of the data
%	center industry and its energy consumption (2022).
%	
%	\bibitem{schwartz2019green}
%	R.~Schwartz, J.~Dodge, N.~A. Smith, O.~Etzioni, Green ai (2019).
%	
%	\bibitem{vinuesa2020role}
%	R.~Vinuesa, {\it et~al.\/}, {\it The role of artificial intelligence in
%		achieving the {S}ustainable {D}evelopment {G}oals\/}, {\it Nature
%		Communications\/} {\bf 11}, 1 (2020).
%	
%	\bibitem{zhou2020hulk}
%	X.~Zhou, Z.~Chen, X.~Jin, W.~Y. Wang, {\it HULK: An Energy Efficiency Benchmark
%		Platform for Responsible Natural Language Processing\/}, {\it arXiv preprint
%		arXiv:2002.05829\/}  (2020).
%	
%	\bibitem{Dalgren2019GreenMLA}
%	A.~Dalgren, Y.~Lundeg{\aa}rd, {\it GreenML : A methodology for fair evaluation
%		of machine learning algorithms with respect to resource consumption\/}
%	(2019).
%	
%	\bibitem{GarciaMartin2019Estimationenergyconsumption}
%	E.~Garc{\'\i}a-Mart{\'\i}n, C.~F. Rodrigues, G.~Riley, H.~Grahn, {\it
%		Estimation of energy consumption in machine learning\/}, {\it Journal of
%		Parallel and Distributed Computing\/} {\bf 134}, 75 (2019).
%	
%	\bibitem{real2019regularized}
%	E.~Real, A.~Aggarwal, Y.~Huang, Q.~V. Le, {\it Regularized evolution for image
%		classifier architecture search\/}, {\it Proceedings of the aaai conference on
%		artificial intelligence\/} (2019), pp. 4780--4789.
%	
%	\bibitem{krizhevsky2012imagenet}
%	A.~Krizhevsky, I.~Sutskever, G.~E. Hinton, {\it Imagenet classification with
%		deep convolutional neural networks\/}, {\it Advances in neural information
%		processing systems\/} {\bf 25}, 1097 (2012).
%	
%	\bibitem{IFR2019}
%	{\relax International Federation of Robotics}, {\it World Robotics 2019
%		Industrial Robots\/} (IFR Statistical Department, 2019).
%	
%	\bibitem{sirkin2015}
%	H.~L. Sirkin, M.~Zinser, J.~Rose, How robots will redefine competitiveness
%	(2015). Retrieved March 8, 2016 from: \url{https://goo.gl/YxPfyF}.
%	
%	\bibitem{fraunhofer2016}
%	{\relax Fraunhofer ISE}, Net installed electricity generation capacity in
%	germany. Retrieved March 9, 2016 from:
%	\url{https://www.energy-charts.de/power_inst.htm}.
%	
%	\bibitem{tobe2015}
%	F.~Tobe, Why cobots will be a huge innovation and growth driver for robotics
%	industry (2015). Retrieved April 5, 2016 from: \url{http://goo.gl/hRG5Du}.
%	
%	\bibitem{IFR2015}
%	{\relax International Federation of Robotics}, Service robot statistics.
%	Retrieved April 5, 2016 from:
%	\url{http://www.ifr.org/service-robots/statistics/}.
%	
%	\bibitem{schroder2014}
%	S.~Schr\"oder, Optimized movements: Ballet of the bots (2014). Retrieved March
%	8, 2016 from: \url{http://goo.gl/0Ir231}.
%	
%	\bibitem{CUT2015Smoothrobotmovements}
%	{\relax Chalmers University of Technology}, Smooth robot movements reduce
%	energy consumption by up to 40 percent (2015). Retrieved March 8, 2016 from:
%	\url{www.sciencedaily.com/releases/2015/08/150824064923.htm}.
%	
%	\bibitem{Mohammed2014MinimizingEnergyConsumption}
%	A.~Mohammed, B.~Schmidt, L.~Wang, L.~Gao, {\it Minimizing Energy Consumption
%		for Robot Arm Movement\/}, {\it Procedia CIRP\/} {\bf 25}, 400 (2014).
%	
%	\bibitem{Chemnitz2011Analyzingenergyconsumption}
%	M.~Chemnitz, G.~Schreck, J.~Krüger, {\it Analyzing energy consumption of
%		industrial robots\/}, {\it Emerging Technologies Factory Automation (ETFA),
%		2011 IEEE 16th Conference on\/} (2011), pp. 1--4.
%	
%	\bibitem{Haddadin2014SystemzumErstellen}
%	S.~Haddadin, System zum erstellen von steuerungsdatens\"atzen f\"ur roboter
%	(2014). German Patent {DE} 10 2014 112 639 B4 2018.02.08.
%	
%	\bibitem{Haddadin2015Systemgeneratingsets}
%	S.~Haddadin, System for generating sets of control data for robots (2015).
%	European Patent {EP} 3 189 385 {B}1.
%	
%	\bibitem{Garavan2012CollectiveLearning}
%	T.~N. Garavan, R.~Carbery, {\it Collective Learning\/} (Springer US, Boston,
%	MA, 2012), pp. 646--649.
%	
%	\bibitem{levine2018learning}
%	S.~Levine, P.~Pastor, A.~Krizhevsky, J.~Ibarz, D.~Quillen, {\it Learning
%		hand-eye coordination for robotic grasping with deep learning and large-scale
%		data collection\/}, {\it The International journal of robotics research\/}
%	{\bf 37}, 421 (2018).
%	
%	\bibitem{rudin2022learning}
%	N.~Rudin, D.~Hoeller, P.~Reist, M.~Hutter, {\it Learning to walk in minutes
%		using massively parallel deep reinforcement learning\/}, {\it Conference on
%		Robot Learning\/} (PMLR, 2022), pp. 91--100.
%	
%	\bibitem{flairop2023}
%	K.~I. f\"ur Technologie, {FLAIROP: Federated Learning for Robotic Picking},
%	\url{https://flairop.com/} (2023).
%	
%	\bibitem{Kaelbling2020foundationefficientrobot}
%	L.~P. Kaelbling, {\it The foundation of efficient robot learning\/}, {\it
%		Science\/} {\bf 369}, 915 (2020).
%	
%	\bibitem{statista_ir_cobot_share}
%	Statista, Share of traditional and collaborative robot unit sales worldwide
%	from 2018 to 2022 (2020).
%	
%	\bibitem{montaqim2015}
%	A.~Montaqim, Top 9 industrial robot companies and how many robots they have
%	around the world (2015). Retrieved March 8, 2016 from:
%	\url{http://goo.gl/QEIBr2}.
%	
%	\bibitem{fanuc2015}
%	{\relax FANUC America}, Fanuc announces record-breaking 400,000 robots sold
%	worldwide (2015). Retrieved March 8, 2016 from:
%	\url{http://www.fanucamerica.com/FanucAmerica-news/Press-releases/PressReleaseDetails.aspx?id=76}.
%	
%	\bibitem{yaskawa2014}
%	{\relax Motoman}, 7 things you may not know about yaskawa (2014). Retrieved
%	March 8, 2016 from:
%	\url{http://www.motoman.com/blog/index.php/7-things-may-know-yaskawa/}.
%	
%	\bibitem{ABB2015}
%	{\relax ABB}, {ABB Robotics} (2015). Retrieved March 8, 2016 from:
%	\url{http://new.abb.com/products/robotics}.
%	
%	\bibitem{statista_ir_operational_stock}
%	Statista, Operational stock of multipurpose industrial robots worldwide from
%	2010 to 2020 (2023).
%	
%	\bibitem{Heredia2023BreakingEnergyConsumption}
%	J.~Heredia, C.~Schlette, M.~B. Kj{\ae}rgaard, {\it Breaking Down the Energy
%		Consumption of Industrial and Collaborative Robots: A Comparative Study\/},
%	{\it IEEE International Conference on Emerging Technologies and Factory
%		Automation\/} (IEEE, 2023).
%	
%\end{thebibliography}
% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
\textbf{Acknowledgments:}
We thank Carlos Magno C. O. Valle for his valuable feedback and support throughout the research process. \textbf{Funding:} This work was supported by the Alfried Krupp von Bohlen und Halbach Foundation. \textbf{Author contributions:} S. Haddadin conceived the fundamental concept of collective learning and hypothesized its effects on learning acceleration and energy minimization. S. Haddadin and F. Díaz Ledezma jointly developed the mathematical framework. F. Díaz Ledezma implemented and conducted all experiments and analyzed the data. Both authors interpreted the results, conceptualized the study, and co-wrote the manuscript. All authors have read and approved the final version of the paper. \textbf{Competing interests:} The authors declare no competing interests. 
\textbf{Data and materials availability:} All data supporting the findings of this study are available in the main text or the Supplementary Materials. Robot power consumption data and other datasets generated in this work will be made publicly available in a dedicated repository upon publication.

%The datasets generated and analyzed in the current study are available at \url{https://github.com/mecafdl/pigraphs_body_morphology}. Requests for additional materials should be addressed to S. Haddadin.

% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
 \newpage
 \beginsupplement
 \section*{Supplementary Materials}\label{sec:supplementary_materials}
 \input{nmi_supplementary.tex}

\end{document}