% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
\section{Mathematical framework}\label{sec:transfer_learning}
In this section we model the scaling of energy and time demand that results from the use of a set of multiple robots performing numerous skills.

% ===================================================================================================
\subsection{Energy and time demand for learning skills}
% ---
\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.95\columnwidth]{fig/power_per_episode.pdf}
	\caption{Power consumption per episode.}
	\label{fig:power_per_episode}
\end{figure}
%---
\begin{tcolorbox}
	\begin{definition}\label{definition:complexity}
		The complexity $c_j$ of a skill $ s_j $  is the number of trial episodes $n$ needed to successfully learn the skill; i.e., all actions and states visited until a stopping criterion is reached. 
	\end{definition}
\end{tcolorbox}
% ---

%To simplify the analysis we make the conservative assumption that the power $P_0$ required by any given robot to learn of a skill is constant. Furthermore,% ---
To simplify the analysis consider the following conservative assumption
% ---
\begin{tcolorbox}
	\begin{assumption}\label{assumption:time}
		Given a large number of robots performing a large number of skills, the average power $P_0$ required by any given robot during learning and the average time $\Delta t$ allocated to the execution of every trial episode $n$ are constant, see Fig.~\ref{fig:power_per_episode}.
	\end{assumption}
\end{tcolorbox}
% ---
% ---------------------------------------------------------------------------------------------------
\subsubsection{\textbf{Energy requirement}}
Under Asm.~\ref{assumption:time}, the energy consumption of the $n$-th episode $e_j(n)$ is simply
% ---
\begin{equation}\label{eq:energy_per_episode}
    e_j(n) = \underbrace{P_0\cdot \Delta t}_{\text{constant}} = e_0.
\end{equation}
% ---
Consequently, the energy consumed by a robot learning the skill $ s_j $ is directly proportional to the complexity; i.e.
% ---
\begin{equation}\label{eq:energy_per_skill}
    E_j =\sum_{n=1}^{c_j} e_j(n) = e_0 \cdot c_j.
\end{equation}
% ---
Having $\mathcal{S}$ represent the set of all \emph{to-be-learned} skills, with $|\mathcal{S}| = N_\mathcal{S}$; then, the energy spent on learning $\mathcal{S}$, if no knowledge transfer is happening, is
% ---
\begin{equation}\label{eq:total_energy}
	E_{\mathcal{S}} = \sum_{j=1}^{{N_{\mathcal{S}}}} E_j = e_0 \sum_{j=1}^{{N_{\mathcal{S}}}} c_j%N_{\mathcal{T}} \cdot e_0 \cdot c_j 
\end{equation}
% ---
% ---------------------------------------------------------------------------------------------------
\subsubsection{\textbf{Time requirement}}
Similarly, the total learning time $T_{\mathcal{S}}$ for a simple agent is
% ---
\begin{equation}\label{eq:total_energy}
	T_{\mathcal{S}} = \Delta t \sum_{j=1}^{{N_{\mathcal{S}}}} c_j.
\end{equation}
% ---
% ===================================================================================================
\begin{figure}[!t]
	\centering
	\includegraphics[width=0.95\columnwidth]{fig/skill_similarity.pdf}
	\caption{Similar skills in $\mathcal{S}$ can be grouped into clusters $\mathcal{Z}_k$.}
	\label{fig:skill_similarity}
\end{figure}
\subsection{Similarity and knowledge}
%---
\begin{tcolorbox}
	\begin{assumption}\label{assumption:skill_clustering} If the degree of similarity among a set of skills is comparable, the exchange of acquired knowledge from these skills expedites the overall learning process.
		\end{assumption}
\end{tcolorbox}
% ---
Following Asm.~\ref{assumption:skill_clustering}, let $\mathcal{Z}_k \subset \mathcal{S}$ be a subset of $N_{\mathcal{Z}_k}$ skills that share high similarity; i.e. a \emph{cluster} of skills, see Fig.~\ref{fig:skill_similarity}. Furthermore, consider another set $\mathcal{\zeta}_k \subset \mathcal{Z}_k$ that denotes already learned skills from $\mathcal{Z}_k$. Asm.~\ref{assumption:skill_clustering} implies that the $j$-th skill in the $k$-th cluster $s_{j,k} \in \mathcal{Z}_k$ can always benefit from the knowledge contained in $\mathcal{\zeta}_k$. This implies that the more skills enter $\mathcal{\zeta}_k$, the less knowledge about $ s_{j,k} $ will remain to be learned.

Now, we introduce a function $\bar{\sigma}_{j,k}\left(n\right)\in [0,1]$ that expresses the knowledge about a skill $s_{j,k} \in \mathcal{Z}_k\textbackslash \mathcal{\zeta}_k$ that \textbf{is not} contained in $\mathcal{\zeta}_k$. The function $\bar{\sigma}_{j,k}(\cdot)$ satisfies:
% ---
\begin{itemize}
	\item $\bar{\sigma}_{j,k}\left(n\right) = 1$, if $\mathcal{\zeta}_k=\emptyset$ or if it does not contain knowledge about the skill $s_{j,k}$
	\item $\bar{\sigma}_{j,k}\left(n\right) = 0$, if \emph{all} the knowledge about skill $s_{j,k}$ is contained in $\mathcal{\zeta}_k$
\end{itemize} 
% ---
Conceptually, $\bar{\sigma}_ {j,k}\left(\cdot\right)$ is the fraction of knowledge from ${\mathcal{Z}_k}$ that remains to be learned.

% ---------------------------------------------------------------------------------------------------
\subsubsection{\textbf{Leveraging the acquired knowledge}}
To evaluate the effect of knowledge exchange during learning we introduce a reference quantity called the skill fundamental complexity.
% ---
\begin{tcolorbox}
	\begin{definition}\label{assumption:fundamental_complexity}
		The \emph{fundamental complexity} $c_0$ describes the maximum number of trial episodes required to learn \emph{any} skill.
	\end{definition}
\end{tcolorbox}
% ---
If, in learning a skill $ s_{j,k} $, a robot uses the knowledge contained in $\mathcal{\zeta}_k$; then, two effects take place:
\begin{enumerate}
	\item There is less remaining knowledge, reflected in the initial value; i.e. $\bar{\sigma}_{j,k}(0) < 1$
	\item Knowledge acquisition is accelerated
\end{enumerate}
%associated complexity $ c_{j,k} $ is necessarily smaller than the fundamental complexity $c_{0}$; i.e. $c_{j,k} < c_0~\forall j>1$.
This implies that the remaining knowledge scales down as a function of the number of learned skills $N_{\zeta_k}=|\mathcal{\zeta}_k|$. As a consequence, the complexity $c_{j,k}$ of said skill is smaller than the the fundamental complexity $c_0$.%, as exemplified in Fig.~\ref{fig:complexity_per_cardinality}. 

The effects of knowledge exchange lead us to introduce another assumption.
% ---
\begin{tcolorbox}
	\begin{assumption}\label{assumption:exponential_decrease} The knowledge function $\bar{\sigma}_{j,k}(\cdot)$ has a monotonically decreasing behavior.
	\end{assumption}
\end{tcolorbox} 
% ---
\noindent

% ---
%\begin{subequations}\label{eq:simple_knowledge_dynamics}
%	\begin{alignat}{2}
%		\dot{\bar{\sigma}}_{j,k}\left(n\right) &= -\alpha r f\left(N_{\zeta_k}\right) \bar{\sigma}_{j,k}\left(n\right)\\
%		\bar{\sigma}_{j,k}(0) &= g\left(N_{\zeta_k}\right)
%	\end{alignat}
%\end{subequations}
An idealization of these behavior can be modeled via the linear homogeneous differential equation.
\begin{tcolorbox}
	\begin{definition}\label{assumption:ode_model}
		The remaining knowledge function $\bar{\sigma}_{j,k}$ is a modeled as a first order linear differential equation defined as
		\begin{subequations}\label{eq:simple_knowledge_dynamics}
			\begin{alignat}{2}
				\dot{\bar{\sigma}}_{j,k}\left(n\right) &= -f_{j,k} \left(N_{\zeta_k} \right) \bar{\sigma}_{j,k}\left(n\right)\\
				\bar{\sigma}_{j,k}(0) &= g_{j,k} \left(N_{\zeta_k}\right)
			\end{alignat}
		\end{subequations}
	\end{definition}
\end{tcolorbox} 
% ---
This model is a function of the trial episodes $n$ and is parameterized by the number of already learned skills $N_{\zeta_k}$. The solution to \eqref{eq:simple_knowledge_dynamics} is given by
% ---
\begin{equation}\label{eq:knowledge_exponential_form}
	\boxed{\bar{\sigma}_{j,k}(n) = g_{j,k}\left(N_{\zeta_k}\right) e ^{-f_{j,k}\left(N_{\zeta_k}\right) n} \in (0,1]}
\end{equation}
% ---
and meets the desired behavior in Asm.~\ref{assumption:exponential_decrease},Â¨ see Fig.~\ref{fig:knowledge_idealization}. The function $f_{j,k}\left(N_{\zeta_k}, r\right)$ models one of the effects resulting from the exploitation of the knowledge available in $\zeta_k$, namely, the increase of the learning rate. The second effect, i.e. the reduction in the initial remaining knowledge $\bar{\sigma}_{j,k}(0)$ is controlled by the term $g_{j,k}\left(N_{\zeta}\right)$, which is also dependent on the number of learned skills.
% ---
\begin{figure}[!t]
	\centering
	\includegraphics[width=0.95\columnwidth]{fig/knowledge_idealization.pdf}
	\caption{Remaining knowledge to learn a new skill $s_{j,k}$. The learning threshold $\epsilon$ represents when the remaining knowledge is negligible and $s_{j,k}$ is considered as learned.}
	\label{fig:knowledge_idealization}
\end{figure}
% ---
% ===================================================================================================
\subsection{Knowledge sharing under different learning paradigms}
%The following assumptions are analogous to average behavior and imply that a suitable scaling strategy is available and executed.
The following assumptions are analogous to an average behavior that stems from considering comparable EAI agents and a balanced ordering and segregation of the skills in $\mathcal{S}$ according to their similarity.
% ---
\begin{tcolorbox}
	\begin{assumption}\label{assumption:agent_similarity}
		Every agent has the same capabilities and energetic cost.
	\end{assumption}
\end{tcolorbox}
% %---
% \begin{tcolorbox}
% 	\begin{assumption}\label{assumption:skill_clustering} When the degree of similarity among a set of skills is comparable, they can be clustered together.
% 		\end{assumption}
% \end{tcolorbox}
% % ---
\begin{tcolorbox}
	\begin{assumption}\label{assumption:cluster_size}
		Every cluster $\mathcal{Z}_{k}$ contains the same number $N_{\mathcal{Z}} $ of skills.
	\end{assumption}
\end{tcolorbox}
% ---
\begin{tcolorbox}
	\begin{assumption}\label{assumption:cluster_transferability}
		The knowledge transferability between skills ---modeled by $\eta$ and $\delta$--- is assumed to be equal; as is transferability factor $\beta_{k}$ between skill clusters.
	\end{assumption}
\end{tcolorbox}

\begin{tcolorbox}
	\begin{assumption}\label{assumption:enabling_agorithms}
		The different learning paradigms that exploit the knowledge collected by one or several EAI agents are reliant on the existence of advanced control and machine learning algorithms designed to inherently use this knowledge.
	\end{assumption}
\end{tcolorbox}

% ---------------------------------------------------------------------------------------------------
\subsubsection{\textbf{Isolated learning (Iso)}} A robot learns each skill in $\mathcal{Z}_k$ one after another from the ground up, disregarding the accumulating knowledge from already learned skills. In such a case the rate of convergence and the initial remaining knowledge for all skills are given by
% ---		
\begin{subequations}\label{eq:fg_isolated}
	\begin{alignat}{2}
		f_{j,k}\left(\cdot \right) &=  -\alpha \\
		g_{j,k}\left(\cdot \right) &= 1,
	\end{alignat}
\end{subequations}
% ---
where $ \alpha>0$ models the rate at which a robot in isolation learns any given skill. Relying on Asm.~\ref{assumption:agent_similarity} we can assign a value to $\alpha$ by using the fundamental complexity $c_0$ as follows
% ---
\begin{equation}\label{eq:isolated_learning_rate}
	\alpha = -\frac{1}{c_0}\text{log}(\epsilon).
\end{equation}
% ---
The energy required by one single robot to learn the skills in the cluster $\mathcal{Z}_k$ is given by
% ---
 \begin{align}
     \begin{split}
       E^{(Iso)}_{\mathcal{Z}_k} &= \sum_{j=1}^{N_{\mathcal{Z}}} E^{(Iso)}_j= N_{\mathcal{Z}_k}  e_{0} \cancelto{c_{0}}{c_{j,k}} = N_{\mathcal{Z}} e_{0}  c_0
     \end{split}
 \end{align}
%-- 
If $\mathcal{S}$ is divided into $\left\lbrace \mathcal{Z}_k \right\rbrace^{N_\mathcal{K}}_{k=1} $ clusters, the total energy to learn the universe of skills is simply
% ---
\begin{equation}
	E^{(Iso)}_{\mathcal{S}} = N_\mathcal{K} N_{\mathcal{Z}} e_{0}  c_0.
\end{equation}
% ---
\paragraph*{Multi agent case}
Notice that using a batch of $m$ robots to learn the same number of skills in parallel does not bring about any energy reductions since
% ---
\begin{equation}
    ^{\lvert \lvert}E^{(Iso)}_\mathcal{S}= \underbrace{m}_{\text{robots}}\cdot \overbrace{\frac{1}{m}E^{(Iso)}_\mathcal{S}}^{\text{energy per robot}} = E^{(Iso)}_\mathcal{S}.
\end{equation}
% ---


%---
% \begin{figure}[!ht]
% 	\centering
% 	\includegraphics[width=0.99\columnwidth]{tex/fig/single_incremental_knowledge.pdf}
% 	\caption{Knowledge sharing in incremental learning. A single agent leverages previously acquired knowledge from other learned skills in $\mathcal{Z}$.}
% 	\label{fig:single_incremental_knowledge}
% \end{figure}

% ---
\begin{figure}[!t]
	\centering
	\includegraphics[width=0.95\columnwidth]{fig/intra_skill_learning.pdf}
	\caption{Incremental learning benefits from the significant similarity of skills belonging to the same cluster.}
	\label{fig:intra_skill_learning}
\end{figure}
% ---
% ---
\begin{figure*}[!htb]
	\centering
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.45\textwidth]{fig/cluster_to_cluster_knowledge_transfer.pdf} \label{fig:cluster_to_cluster_knowledge_transfer}}  
	\hfill	
	\subfloat[]{\includegraphics[width= 0.45\textwidth]{fig/cluster_to_cluster_knowledge_transfer_parallel.pdf} \label{fig:cluster_to_cluster_knowledge_transfer_parallel}}
	\hspace*{\fill}
	\caption[] {\label{fig:tranfer_learninhg} Transfer learning. \subref{fig:cluster_to_cluster_knowledge_transfer} Transfer of knowledge from different origin clusters to the target cluster,  \subref{fig:cluster_to_cluster_knowledge_transfer_parallel} using many robots (e.g. two robots $r_1$ and $r_2$) without knowledge exchange among them only subdivides the problem.}
\end{figure*}
% ---
% ---------------------------------------------------------------------------------------------------
\subsubsection{\textbf{Incremental learning (I)}}
\textcolor{red}{It corresponds to the continuous aggregation and exchange of knowledge from \textbf{INTRA-cluster} skills.} Referring back to Asm.~\ref{assumption:skill_clustering}, the knowledge from skills belonging to a cluster ${\mathcal{Z}_k}$ can be be leveraged by an agent in virtue of their significant similarity. As depicted in Fig.~\ref{fig:intra_skill_learning}, a robot ($r_1$ in this case) learns every skill in $\mathcal{Z}_1$ with a rate $\alpha$ ---the self loops--- but also passes the acquired knowledge to the subsequent skills. The effect of incremental learning on the knowledge collection rate can be modeled to be directly proportional to the number of learned skills as
% ---
\begin{equation}\label{eq:f_function}
	f_{j,k}\left(N_{\zeta_k}\right) = -\alpha\left(\eta N_{\zeta_k} + 1 \right) ,
\end{equation}
% ---
where $\eta$ represents the efficiency of knowledge exchange from $\zeta_k$ to $s_{j,k}$. Different potential models might be used to model the depletion of the initial remaining knowledge represented by $g_{j,k}\left(N_{\zeta_k}\right)$, e.g. a linear decay rate, our expectation is that, under the assumption that a learning strategy involving the ordering of skills according to similarity and their balanced distribution in the different clusters, $g_{j,k}\left(N_{\zeta_k}\right)$ might naturally resemble an exponential decay that is strongly dependent on $N_{\zeta_k}$. Such considerations motivate our choice of the following function
% ---
\begin{equation}\label{eq:g_function}
	g_{j,k}\left(N_{\zeta_k}\right) = e^{-\delta N_{\zeta_k}},
\end{equation}
%---
again with a term $\delta$ controlling the rate at which the exponential converges. Similar to $\alpha$, $\delta>0$, from Asm.~\ref{assumption:cluster_size} it can be defined as 
% ---
\begin{equation}\label{eq:delta}
	\delta = -\frac{1}{N_\mathcal{Z}}\text{log}(\epsilon).
\end{equation}
% ---
Essentially, such choice of $\delta$ implies that the remaining knowledge in a cluster after seeing all its skills is negligible. Via the exchange factors $(\eta,\delta)$, in incremental learning the knowledge about every new skill gets gradually increased by leveraging previous knowledge, resulting in
% ---
\begin{equation*}\label{eq:remaining_knowledge__IL}
	\bar{\sigma}^{(I)}_{i,j}(n) = e^{-\alpha  \left(\eta N_{\zeta_k}+1\right) n} e^{-\delta N_{\zeta_k}},
\end{equation*}
% ---
As the complexity $c_{j,k}$ of a skill can also be interpreted as the number of trial episodes such that the remaining knowledge goes below a threshold $\epsilon$; i.e.
% ---
\begin{equation*}
	\bar{\sigma}^{(I)}_{i,j}(n) \rvert_{n \ge c_{j,k}} \leq \epsilon,
\end{equation*}
% ---
then under this scheme the complexity $c_{j,k}$ to learn a new is skill in the cluster results in
%\begin{equation}\label{eq:complexity_IL}
%	c^{(I)}_{j,k} = -\frac{\text{log}(\epsilon)}{\alpha \eta (N_{\zeta_k}+ 1)}.
%\end{equation}
\begin{equation}\label{eq:complexity_IL}
	c^{(I)}_{j,k} = -\frac{\text{log}(\epsilon) - \text{log}\left(\bar{\sigma}^{(I)}_{j,k}(0)\right)}{\alpha (\eta N_{\zeta_k}+ 1)} = -\frac{\text{log}(\epsilon) + \delta N_{\zeta_k}}{\alpha (\eta N_{\zeta_k}+ 1)}  .
\end{equation}
% ---
The total number of trial episodes $ C_k $ that an agent following an incremental learning strategy needs to learn the $N_{\mathcal{Z}_k}$ skills in a cluster $ \mathcal{Z}_k $ is given by
% ---
\begin{align}\label{eq:total_episodes_incremental}
	\begin{split}
		C^{(I)}_k &= \sum^{N_{\mathcal{Z}}}_{j=1} c^{(I)}_{j,k}.
	\end{split}
\end{align}
% ---

\paragraph*{Multi-agent case}
If $m$ robots are used in parallel to divide the load of learning the tasks then
% ---
\begin{align}
	\begin{split}
		{}^{\lvert \rvert}C^{(I)}_k &= m\sum^{\frac{N_{\mathcal{Z}}}{m}}_{j=1} c^{(I)}_{j,k}.
	\end{split}
\end{align}
In essence, using $m$ robots without exchanging knowledge only subdivides the learning in every cluster into $m$ smaller problems without adding any additional benefit to the rate at which knowledge is acquired. 

\subsubsection{\textbf{Transfer learning (TL)}}
\textcolor{red}{It refers to the one-time \textbf{INTER-cluster} exchange of knowledge}. Considering $\mathcal{K} = \{ \mathcal{Z}_k \}^{N_\mathcal{K}}_{k=1}$ to be the set of all available skill clusters, TL represents the exchange of knowledge from the skills learned in different \emph{origin} clusters $\mathcal{O} = \{ \mathcal{Z}_1,\mathcal{Z}_2,\ldots,\mathcal{Z}_{k-1} \}$ to the skills that will be learned in a \emph{destination} cluster $\mathcal{Z}_k$ (see Fig.~\ref{fig:cluster_to_cluster_knowledge_transfer}). Concretely, the effect that TL has on the skills of the destination cluster is the reduction of the initial remaining knowledge and the increase of the initial learning rate for all the skills in the $k$-th cluster via the parameter $\beta_k$; i.e.
% ---
\begin{equation}\label{eq:f_function_transfer}
	f_{j,k}\left(N_{\zeta_k}\right) = -\alpha \left( \frac{\eta N_{\zeta_k} + 1}{1 - \beta_k} \right),
\end{equation}
% ---
and
% ---
\begin{equation}\label{eq:g_function_transfer}
	g_{j,k}\left(N_{\zeta_k}\right) = (1-\beta_k) e^{-\delta N_{\zeta_k}}.
\end{equation}
%---
In essence, $\beta_k$ is the head start granted by knowledge transfer from other clusters to the skills in $\mathcal{Z}_k$. We argue that  $0<\beta_{k} < 1$ since it represents the \emph{aggregated} knowledge exchange factor from the different origin clusters $\mathcal{Z}_{c}$ to the target cluster $\mathcal{Z}_{k}$. Let $0<\beta_{c} < 1$ be the transfer contribution factor of a single origin cluster $\mathcal{Z}_c$. Additionally, consider that
% ---
\begin{equation}
	\sum\limits_{c=1}^{N_\mathcal{K}}\beta_{c} \leq 1,
\end{equation}
% --
as $1$ represents all the knowledge in $\mathcal{S}$. Asm.~\ref{assumption:cluster_transferability} implies that $\beta_c$ is equal for all the clusters. In this work we select $\beta_c = 1/N_\mathcal{K}$ for simplicity. The aggregated transfer factor $\beta_k$ is the sum of the individual factors from the already-visited clusters; i.e.
% ---
\begin{equation}
	\beta_{k}= \left(k-1\right)\beta_c = \left(k-1\right)\frac{1}{N_\mathcal{K}}.
\end{equation}
% ---

Consequently, the remaining knowledge when transfer and incremental learning are used in conjunction is
% ---
\begin{equation*}\label{eq:remaining_knowledge__ITL}
	\bar{\sigma}^{(I)}_{j,k}(n) = \left(1- \beta_k\right) e^{-\alpha  \left(\frac{ \eta N_{\zeta_k}+1}{1 - \beta_k}\right) n} e^{-\delta N_{\zeta_k}},
\end{equation*}
% ---
Similar to incremental learning the complexity to learn a skill in transfer learning is
\begin{equation}\label{eq:skill_complexity_TL}
	c^{(IT)}_{j,k} = -\frac{1 - \beta_{k}}{\alpha (\eta N_{\zeta_k}+ 1)}\left[\text{log}(\epsilon) + \delta N_{\zeta_k} - \text{log}(1 - \beta_{k})\right]
\end{equation}
% ---
and the total number of episodes  $ C_k $ that an agent requires to learn the $N_{\mathcal{Z}_k}$ skills is merely their sum
% ---
\begin{align}\label{eq:total_episodes_transfer}
	\begin{split}
		C^{(IT)}_k &= \sum^{N_{\mathcal{Z}}}_{j=1} c^{(T)}_{j,k}.
	\end{split}
\end{align}
% --- 

\paragraph*{Multi-agent case}
If $m$ robots are used in parallel to divide the load of learning the tasks then
% ---
\begin{align}
	\begin{split}
		{}^{\lvert \rvert}C^{(IT)}_k &= m\sum^{\frac{N_{\mathcal{Z}}}{m}}_{j=1} c^{(IT)}_{j,k}.
	\end{split}
\end{align}
% ---
This case is depicted on Fig.~\ref{fig:cluster_to_cluster_knowledge_transfer_parallel}, where two robots $ r_1$ and $r_2$ learn skills in four different clusters. The shaded areas are the subclusters of skills learned by each robot. Since they do not share knowledge between them, each robot has access only to the knowledge it has collected and cannot benefit from one another. 

% ---------------------------------------------------------------------------------------------------
\subsubsection{\textbf{Collective learning (C)}}
% ---
\begin{figure}[!th]
	\centering
	\includegraphics[width=0.7\columnwidth]{fig/cl_example_figure.pdf}
	\caption{Exchange of knowledge between EAI agents enables collective learning.}
	\label{fig:cl_example_figure}
\end{figure}
% ---
In this paradigm a batch of robots $\left \lbrace r_i \right \rbrace^m_{1}$ learn different skills concurrently. Furthermore, it is assumed that under collective learning
\begin{itemize}
	\item an inter-agent communication protocol/infrastructure is in place that
	\item enables agents to concurrently transfer and integrate the self-acquired and received knowledge to
	\item incrementally speed up the learning of all the agents as a whole.
\end{itemize}
% ---
Naturally, the collective learning paradigm involves a complex scheduling problem to determine the optimal skill distribution and inter-agent knowledge sharing strategy. We have not tackled this problem and thus we refer back to Assumptions~\ref{assumption:agent_similarity},~\ref{assumption:cluster_size}, and~\ref{assumption:cluster_transferability} that suggest an average behavior.

Fig.~\ref{fig:cl_example_figure} illustrates the CL concept, where the self loop represents the dynamics of a single robot learning (at a rate $\alpha$). The exchange of knowledge across agents is represented via the cross-couplings weighted by a parameter $\gamma$ that models how efficient the bidirectional pairwise knowledge exchange is. Similar to transfer learning, if two robots exchange knowledge about skills with low similarity (i.e. skills in different clusters), then $\gamma$ is scaled by the inter-cluster transferability  parameter $\beta$. In CL \eqref{eq:simple_knowledge_dynamics} is extended to 
% ---
\begin{subequations}\label{eq:collective_knowledge_dynamics}
	\begin{alignat}{2}
		\dot{\bar{\bm{\sigma}}}^{(C)}_{j,k}\left(n\right) &= \overbrace{\left[  f_{j,k}\left(N_{\zeta_k},r\right) \bm{I} + \gamma \bm{A} \odot \bm{B}  \right]}^{\bar{\bm{A}}\left(N_{\zeta_k}\right)} \bar{\bm{\sigma}}_{j,k}\left(n\right)\\
		\bar{\bm{\sigma}}^{}_{j,k}(0) &= g_{j,k}\left( N_{\zeta_k}, r\right) \bm{I},
	\end{alignat}
\end{subequations}
% ---
where $r=m$ is the number of robots that exchange knowledge among them. This implies that now $\bar{\bm{\sigma}}^{}_{j,k} \in \mathbb{R}^r$ is a vector that represents the dynamics of the remaining knowledge of all the $m$ skills being concurrently learned. $\bm{A} \in \mathbb{R}^{r \times r}$ is a zero-diagonal symmetric adjacency matrix whose entry $(\bm{A})_{i,j} = 1$ if robot $i$ exchanges knowledge with robot $j$ an $(\bm{A})_{i,j} = 0$ if it does not. The term $\gamma \in \mathbb{R}_+ $ weighs the knowledge exchange strength among robots. Furthermore, since there may be robots learning skills in different clusters at the same time, the matrix $\bm{B}$, whose entries are $\left(\bm{B}\right)_{i,j} \in \left \lbrace 1, \beta_{k} \right \rbrace$ (with $\beta_{k} = 1/N_\mathcal{K}$), scale down the knowledge contributions between robots from different clusters. Finally, the operator $\odot$ represents the Hadamard product of matrices. The functions $ f(\cdot)$ and $g(\cdot)$ are now also dependent on the number of robots that exchange knowledge, which directly impacts the number of skills that enter $\zeta_k$ after a learning cycle; i.e.
% ---
\begin{equation}\label{eq:f_function_collective}
	f_{j,k}\left(N_{\zeta_k},r\right) = -\alpha \left( \frac{\eta r N_{\zeta_k} + 1}{1 - \beta_k} \right),
\end{equation}
% ---
and
% ---
\begin{equation}\label{eq:g_function_collective}
	g_{j,k}\left(N_{\zeta_k},r\right) = (1-\beta_k) e^{-\delta r N_{\zeta_k}}.
\end{equation}
%---

Given the dynamics matrix of the collective system
% ---
\begin{equation}
	\bar{\bm{A}}\left(N_{\zeta_k}\right) = f\left(N_{\zeta_k},r\right) \bm{I} + \gamma \bm{A} \odot \bm{B} 
\end{equation} 
% ---
it can be proven that there is a coupling strength $\gamma$ that ensures that the remaining knowledge for all skills converges asymptotically to zero. Notice that because of \eqref{eq:f_function_collective}, $\bar{\bm{A}}$ exhibits a dependency of  on the number of seen skills $N_{\zeta_k}$, which is directly influenced by the number of robots $r$ in the collective.

\TODO \textcolor{red}{is there an approximation of the convergence rate of all the skills?}

% ===================================================================================================

%\subsection{Summary}
%
%The equation for incremental learning is equivalent to \eqref{eq:knowledge_exponential_form} with $r=1$ since no inter-agent exchange of knowledge occurs and $\beta_k = 0$,Â¸ as knowledge from other cluster cannot be used.
% ---
%\begin{figure*}[!th]
%	\centering
%	\includegraphics[width=0.95\textwidth]{fig/cluster_learning_sequence.pdf}
%	\caption{The sequence followed to learn the clusters.}
%	\label{fig:cluster_learning_sequence}
%\end{figure*}
% ---
%---
\begin{figure}[!t]
	\centering
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.99\columnwidth]{fig/cluster_learning_sequence.pdf} \label{fig:cluster_learning_sequence}}
	\hspace*{\fill}
	\\	
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.99\columnwidth]{fig/dynamics_isolated_learning.pdf} \label{fig:dynamics_isolated_learning}}  
	\hspace*{\fill}
	\\	
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.99\columnwidth]{fig/dynamics_incremental_learning.pdf} \label{fig:dynamics_incremental_learning}}  
	\hspace*{\fill}	
	\\
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.99\columnwidth]{fig/dynamics_incremental_transfer_learning.pdf} \label{fig:dynamics_incremental_transfer_learning}}  
	\hspace*{\fill}
	\\
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.99\columnwidth]{fig/dynamics_collective_learning.pdf} \label{fig:dynamics_collective_learning}}
	\hspace*{\fill}
	\caption[] {\label{fig:collective_learning} Scenario 1: \subref{fig:cluster_learning_sequence} the skills of each cluster are learned by the $ m$ robots in succession, \subref{fig:dynamics_isolated_learning} isolated learning,  \subref{fig:dynamics_incremental_learning} incremental learning,  \subref{fig:dynamics_incremental_transfer_learning} incremental + transfer learning, \subref{fig:dynamics_collective_learning} collective learning.}
\end{figure}
% ---
\subsection{The effects of the different paradigms}
To show the effect that the different learning paradigms have on energy consumption, consider a scenario in which the skill fundamental complexity is $c_0=100$ episodes with $N_\mathcal{S}= 512$  skills are divided into $N_\mathcal{K}=4$ clusters of $N_\mathcal{Z} = 128$ skills each. Additionally, we consider that $m=32$ robots are available to learn the skills and that a skill is considered learned once the remaining knowledge goes below $\epsilon = 0.01$. In this scenario the robots are used to learn in parallel the skills of each cluster in succession, as shown in Fig.~\ref{fig:cluster_learning_sequence}. The remaining parameters are selected as follows:
% ---
\begin{itemize}
	\item $\alpha =  0.0461$ (in accordance to \eqref{eq:isolated_learning_rate})
	\item $\delta =  0.0360$ (see \eqref{eq:delta})
	\item $\eta= 0.1$
\end{itemize} 
% ---
The remaining knowledge for the four skills learned per robot are shown in Fig.~\ref{fig:collective_learning} in logarithmic scale. Notice that as expected, isolated exhibits the worst performance, always requiring $c_0$ episodes to learn every single skill. Since incremental learning does not benefit from the knowledge from the previously visited clusters, the robot needs to start accumulating knowledge from the beginning every time it moves to a different cluster. This is not the case in transfer learning, as the more cluster the robot has visited the faster a new skill is learned. The speed of knowledge collection is clearly exponentiated with collective learning thanks to the exchange of knowledge among robots. 

To assess how the number of robots affects the total number of trial episodes required to learn all the $N_\mathcal{S}$ skills we use the same parameters as before but vary the number of robots in $m \in \left \lbrace 2,4,8,16,32,64\right \rbrace$. Additionally we considered an additional collective learning scenario in which, unlike the previous case, the total number of available robots is distributed equally among the clusters to benefit from transfer learning at an earlier time during learning. The results are shown in Fig.~\ref{fig:total_episodes_per_n_robots}. 
\begin{figure}[!th]
	\centering
	\includegraphics[width=0.9\columnwidth]{fig/total_episodes_per_n_robots.pdf}
	\caption{Total number of episodes to learn the universe of skills as a function of the available robots.}
	\label{fig:total_episodes_per_n_robots}
\end{figure}




