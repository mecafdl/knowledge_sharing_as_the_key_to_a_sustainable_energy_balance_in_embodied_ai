% ===================================================================================================
%                                                 |                                                 |
%                                                 |                                                 |
% -------------------------------------------- SECTION ---------------------------------------------|
%                                                 |                                                 |
%                                                 |                                                 |
% ===================================================================================================
\section{Use case: Smart factory}\label{sec_use_case}
The goal of this section is to forecast the energy demand that EAI agents following the learning paradigms discussed in Sec.~\ref{sec:learning_paradigms} would have in a prototypical instance of a hypothetical smart factory. In this mock factory a pool $\mathcal{S}$ of $N_\mathcal{S}= 512$ industry relevant skills is divided into $N_\mathcal{K}=4$ clusters of $N_\mathcal{Z} = 128$ skills each. Additionally, consider that $m=32$ robots are available to learn the skills and that a skill is considered learned once the remaining knowledge goes below $\epsilon = 0.01$. For all the skills, the fundamental skill complexity is $c_0 = 100$ episodes.

The power in \eqref{eq:energy_per_episode} is composed by the sum of the power required for basal processes, the power for motion and interaction, and the power for computation and communication; i.e.
% ---
\begin{equation}
    P_0 = P_{BEE}+P_{MIE} + P_{CCE}.
\end{equation}
% ---
To choose $P_{BEE}$, we consider that the smart factory will be populated with state-of-the-art tactile robots, like those listed in Appendix~\ref{sec:app_cobot_ener_consumption}, which require a typical power of about $\unit[40]{W}$. To approximate $P_{MIE}$, we use the fact that, in demanding tasks, the power demand of a cobot like the Franka Emika robot arm can go up to a maximum of about $ \unit[300] {W} $. Finally, to determine $P_{CCE}$, we make the assumption that, to deal with the computing effort that learning new skills will have on the robots' local processors, the smart factory will delegate the computational burden to a remote computing unit (i.e. cloud computing). Thus, we take as reference the work in \cite{Strubell2019EnergyAP}, where a state-of-the-art machine learning algorithm executed in a cluster required $\unit[1,415.78]{W}$ to solve a task. Additionally, without loss of generality, we can assume that each trial episode takes $\Delta t = 60$ seconds to execute. Using these reference values, we can estimate that, when learning a skill, a trial episode has en energetic demand of:
% ---
\begin{equation}
	e_0 = P_0 \Delta t = \left(40 + 300 + 1,415.78\right) \left(60\right) \approx 105~\text{kJ}
\end{equation}
% ---
Regarding the knowledge exchange efficiency constants, they are chosen as follows
% ---
% ---
\begin{itemize}
	\item $\alpha =  0.0461$ (in accordance to \eqref{eq:isolated_learning_rate})
	\item $\delta =  0.0360$ (see \eqref{eq:delta})
	\item $\eta= 0.1$
\end{itemize} 
% ---
%\begin{align}\label{eq:transfer_constants}¸
%\begin{split}
%    \alpha &=1\times10^{-3}\\
%    \beta &=1\times10^{-5}\\
%    \gamma &=1\times10^{-7}    
%\end{split}
%\end{align}
% ---
%Finally, we assume that each episode $n$ contains $k=10,000$ iterations.

% ===================================================================================================

%\subsection{Summary}
%
%The equation for incremental learning is equivalent to \eqref{eq:knowledge_exponential_form} with $r=1$ since no inter-agent exchange of knowledge occurs and $\beta_k = 0$,¸ as knowledge from other cluster cannot be used.
% ---
%\begin{figure*}[!th]
%	\centering
%	\includegraphics[width=0.95\textwidth]{fig/cluster_learning_sequence.pdf}
%	\caption{The sequence followed to learn the clusters.}
%	\label{fig:cluster_learning_sequence}
%\end{figure*}
% ---
%---


\begin{figure*}[!t]
	\centering
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.8\textwidth]{fig/cluster_learning_sequence.png} \label{fig:cluster_learning_sequence}}
	\hspace*{\fill}
	\\	
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.8\textwidth]{fig/dynamics_isolated_learning.png} \label{fig:dynamics_isolated_learning}}  
	\hspace*{\fill}
	\\	
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.8\textwidth]{fig/dynamics_incremental_learning.png} \label{fig:dynamics_incremental_learning}}  
	\hspace*{\fill}	
	\\
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.8\textwidth]{fig/dynamics_incremental_transfer_learning.png} \label{fig:dynamics_incremental_transfer_learning}}  
	\hspace*{\fill}
	\\
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width= 0.8\textwidth]{fig/dynamics_collective_learning.png} \label{fig:dynamics_collective_learning}}
	\hspace*{\fill}
	\caption[] {\label{fig:collective_learning} Scenario 1: \subref{fig:cluster_learning_sequence} the skills of each cluster are learned by the $ m$ robots in succession, \subref{fig:dynamics_isolated_learning} isolated learning,  \subref{fig:dynamics_incremental_learning} incremental learning,  \subref{fig:dynamics_incremental_transfer_learning} incremental + transfer learning, \subref{fig:dynamics_collective_learning} collective learning.}
\end{figure*}
% ---

% ===================================================================================================
\subsection{The skill complexity of the different paradigms}
The remaining knowledge for the four skills learned per robot are shown in Fig.~\ref{fig:collective_learning} in logarithmic scale. With the parameters discussed previously the $m$ robots are used to learn in parallel the $N_\mathcal{Z}$ skills of each cluster in succession, as shown in Fig.~\ref{fig:cluster_learning_sequence}. Notice that as expected, isolated learning (Fig.~\ref{fig:dynamics_isolated_learning}) exhibits the worst performance, always requiring $c_0$ episodes to learn every single skill. Since incremental learning (Fig.~\ref{fig:dynamics_incremental_learning}) does not benefit from the knowledge from the previously visited clusters, a robot $r_i$ needs to start accumulating knowledge from the beginning every time it moves to a different cluster. This is not the case in transfer learning (Fig.~\ref{fig:dynamics_incremental_transfer_learning}), as the more clusters a robot has visited the faster a new skill is learned. The speed of knowledge collection is clearly exponentiated with collective learning (Fig.~\ref{fig:dynamics_collective_learning}) thanks to the exchange of knowledge among the $m$ robots. In comparison to the other learning paradigms, with CL the skills are learned within a few trial episodes in every cluster. 

To assess how the number $m$ of robots affects the total number of trial episodes $C_\mathcal{S}$ required to learn all the $N_\mathcal{S}$ skills we use the same parameters as before but vary $m \in \left \lbrace 2,4,8,16,32,64,128\right \rbrace$. Moreover, we considered an additional collective learning scenario in which, unlike the previous case, the total number of available robots is distributed equally among the clusters to benefit from transfer learning at an earlier time during learning. The results are shown in Fig.~\ref{fig:total_episodes_per_n_robots}. From it, it can be seen that, at first, incremental learning is better than the trivial isolated learning case; however, as the number or robots increases, the skill knowledge is divided among the available robots which implies that less knowledge can be passed, as the pool of learned sills $\zeta_k$ per robot gets smaller. This explains why the total number of trial episodes for IsL and IL approach each other in the limit. TIL exhibits a similar behavior, as the number of robots grows, less cluster knowledge can be collected by each robot and transferred to the next cluster. Indeed, TIL rapidly converges to IL and eventually to IsL. In CL, a similar effect shows that when all robots are learning skills in from the same clusters, as the number of robots grows, the total complexity approaches that of the same number of robots distributed across clusters.

% SUBSECTION ========================================================================================
\subsection{Energy consumption}
Consider that the results in Fig.~\ref{fig:total_episodes_per_n_robots} show the total number of episodes required by each of the $m$ robots. To compute the total energy demand those numbers need to be scaled by the factor $m e_0$, which leads to the consumption shown in Fig.~\ref{fig:total_energy_per_n_robots}.
% ---
\begin{figure}[!t]
	\centering
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width=0.90\columnwidth]{fig/total_episodes_per_n_robots.png}
	\label{fig:total_episodes_per_n_robots}}  
	\hspace*{\fill}
	\\
	\hspace*{\fill}
	\subfloat[]{\includegraphics[width=0.90\columnwidth]{fig/total_energy_per_n_robots.png}
	\label{fig:total_energy_per_n_robots}}
	\hspace*{\fill}
	\caption[] {\label{fig:final_results} The effect of the number of robots: \subref{fig:total_episodes_per_n_robots} Total number of episodes to learn the universe of skills as a function of the available robots and \subref{fig:total_energy_per_n_robots} the total energy consumption.}
\end{figure}
% ---
Undoubtedly, CL shows that it has not only the best energy usage of all the paradigms, but, unlike the rest, the more robots take part in learning the universe of skills, the better overall energy usage.